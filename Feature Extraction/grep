{"Event":"SparkListenerLogStart","Spark Version":"1.5.0"}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"driver","Host":"10.0.1.35","Port":58693},"Maximum Memory":2223023063,"Timestamp":1448824864733}
{"Event":"SparkListenerEnvironmentUpdate","JVM Information":{"Java Home":"/usr/lib/jvm/java-7-openjdk-amd64/jre","Java Version":"1.7.0_85 (Oracle Corporation)","Scala Version":"version 2.10.4"},"Spark Properties":{"spark.akka.timeout":"600","spark.driver.host":"10.0.1.35","spark.kryoserializer.buffer.mb":"2000","spark.broadcast.compress":"false","spark.io.compression.codec":"org.apache.spark.io.SnappyCompressionCodec","spark.eventLog.enabled":"true","spark.driver.port":"54611","spark.rdd.compress":"false","spark.cleaner.ttl":"7200","spark.shuffle.compress":"false","spark.jars":"file:/home/ubuntu/software/HiBench-master/src/streambench/sparkbench/target/streaming-bench-spark_0.1-4.0-SNAPSHOT-jar-with-dependencies.jar,file:/home/ubuntu/software/HiBench-master/src/sparkbench/target/sparkbench-4.0-SNAPSHOT-MR2-spark1.5-jar-with-dependencies.jar","spark.app.name":"grep","spark.scheduler.mode":"FIFO","spark.driver.memory":"4G","spark.default.parallelism":"12","spark.executor.id":"driver","spark.submit.deployMode":"client","spark.master":"spark://10.0.1.35:7077","spark.executor.memory":"4G","spark.eventLog.dir":"/home/ubuntu/storage/logs/HiBench","spark.fileserver.uri":"http://10.0.1.35:56902","spark.externalBlockStore.folderName":"spark-bf582cb3-0582-41a0-a1b4-138e91ba7580","spark.app.id":"app-20151129192104-0031","spark.akka.frameSize":"1000","spark.sql.shuffle.partitions":"12"},"System Properties":{"java.io.tmpdir":"/tmp","line.separator":"\n","path.separator":":","sun.management.compiler":"HotSpot 64-Bit Tiered Compilers","SPARK_SUBMIT":"true","sun.cpu.endian":"little","java.specification.version":"1.7","java.vm.specification.name":"Java Virtual Machine Specification","java.vendor":"Oracle Corporation","java.vm.specification.version":"1.7","user.home":"/home/ubuntu","file.encoding.pkg":"sun.io","sun.nio.ch.bugLevel":"","sun.arch.data.model":"64","sun.boot.library.path":"/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/amd64","user.dir":"/home/ubuntu/software/HiBench-master/workloads/streamingbench/spark/bin","java.library.path":"/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/native/::/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib","sun.cpu.isalist":"","os.arch":"amd64","java.vm.version":"24.85-b03","java.endorsed.dirs":"/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/endorsed","java.runtime.version":"1.7.0_85-b01","java.vm.info":"mixed mode","java.ext.dirs":"/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext","java.runtime.name":"OpenJDK Runtime Environment","file.separator":"/","java.class.version":"51.0","java.specification.name":"Java Platform API Specification","sun.boot.class.path":"/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/rhino.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/classes","file.encoding":"UTF-8","user.timezone":"Etc/UTC","java.specification.vendor":"Oracle Corporation","sun.java.launcher":"SUN_STANDARD","os.version":"3.13.0-46-generic","sun.os.patch.level":"unknown","java.vm.specification.vendor":"Oracle Corporation","user.country":"US","sun.jnu.encoding":"UTF-8","user.language":"en","java.vendor.url":"http://java.oracle.com/","java.awt.printerjob":"sun.print.PSPrinterJob","java.awt.graphicsenv":"sun.awt.X11GraphicsEnvironment","awt.toolkit":"sun.awt.X11.XToolkit","os.name":"Linux","java.vm.vendor":"Oracle Corporation","java.vendor.url.bug":"http://bugreport.sun.com/bugreport/","user.name":"ubuntu","java.vm.name":"OpenJDK 64-Bit Server VM","sun.java.command":"org.apache.spark.deploy.SparkSubmit --master spark://10.0.1.35:7077 --properties-file /home/ubuntu/software/HiBench-master/report/streamingbench/spark/conf/sparkbench/spark.conf --class com.intel.hibench.streambench.spark.RunBench --jars /home/ubuntu/software/HiBench-master/src/streambench/sparkbench/target/streaming-bench-spark_0.1-4.0-SNAPSHOT-jar-with-dependencies.jar /home/ubuntu/software/HiBench-master/src/sparkbench/target/sparkbench-4.0-SNAPSHOT-MR2-spark1.5-jar-with-dependencies.jar /home/ubuntu/software/HiBench-master/report/streamingbench/spark/conf/sparkbench/sparkbench.conf","java.home":"/usr/lib/jvm/java-7-openjdk-amd64/jre","java.version":"1.7.0_85","sun.io.unicode.encoding":"UnicodeLittle"},"Classpath Entries":{"/home/ubuntu/software/spark-1.5.0-bin-hadoop2.6/lib/datanucleus-api-jdo-3.2.6.jar":"System Classpath","/home/ubuntu/conf/":"System Classpath","http://10.0.1.35:56902/jars/streaming-bench-spark_0.1-4.0-SNAPSHOT-jar-with-dependencies.jar":"Added By User","/home/ubuntu/software/spark-1.5.0-bin-hadoop2.6/lib/datanucleus-rdbms-3.2.9.jar":"System Classpath","/home/ubuntu/software/spark-1.5.0-bin-hadoop2.6/lib/spark-assembly-1.5.0-hadoop2.6.0.jar":"System Classpath","/home/ubuntu/software/spark-1.5.0-bin-hadoop2.6/lib/datanucleus-core-3.2.10.jar":"System Classpath"}}
{"Event":"SparkListenerApplicationStart","App Name":"grep","App ID":"app-20151129192104-0031","Timestamp":1448824861343,"User":"ubuntu"}
{"Event":"SparkListenerExecutorAdded","Timestamp":1448824867861,"Executor ID":"0","Executor Info":{"Host":"10.0.1.37","Total Cores":5,"Log Urls":{"stdout":"http://10.0.1.37:8081/logPage/?appId=app-20151129192104-0031&executorId=0&logType=stdout","stderr":"http://10.0.1.37:8081/logPage/?appId=app-20151129192104-0031&executorId=0&logType=stderr"}}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1448824867885,"Executor ID":"2","Executor Info":{"Host":"10.0.1.36","Total Cores":5,"Log Urls":{"stdout":"http://10.0.1.36:8081/logPage/?appId=app-20151129192104-0031&executorId=2&logType=stdout","stderr":"http://10.0.1.36:8081/logPage/?appId=app-20151129192104-0031&executorId=2&logType=stderr"}}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1448824867941,"Executor ID":"3","Executor Info":{"Host":"10.0.1.38","Total Cores":5,"Log Urls":{"stdout":"http://10.0.1.38:8081/logPage/?appId=app-20151129192104-0031&executorId=3&logType=stdout","stderr":"http://10.0.1.38:8081/logPage/?appId=app-20151129192104-0031&executorId=3&logType=stderr"}}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1448824868067,"Executor ID":"1","Executor Info":{"Host":"10.0.1.35","Total Cores":5,"Log Urls":{"stdout":"http://10.0.1.35:8081/logPage/?appId=app-20151129192104-0031&executorId=1&logType=stdout","stderr":"http://10.0.1.35:8081/logPage/?appId=app-20151129192104-0031&executorId=1&logType=stderr"}}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"0","Host":"10.0.1.37","Port":53592},"Maximum Memory":2223023063,"Timestamp":1448824868071}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"2","Host":"10.0.1.36","Port":45285},"Maximum Memory":2223023063,"Timestamp":1448824868087}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"3","Host":"10.0.1.38","Port":52945},"Maximum Memory":2223023063,"Timestamp":1448824868162}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"1","Host":"10.0.1.35","Port":46863},"Maximum Memory":2223023063,"Timestamp":1448824868269}
{"Event":"SparkListenerJobStart","Job ID":0,"Submission Time":1448824870209,"Stage Infos":[{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":2,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824870000\",\"name\":\"filter @ 19:21:10\"}","Parent IDs":[1],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824870000\",\"name\":\"kafka direct stream [0]\\n@ 19:21:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824870000\",\"name\":\"map @ 19:21:10\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[0],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824870000\",\"name\":\"foreachRDD @ 19:21:10\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824870000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":2,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824870000\",\"name\":\"filter @ 19:21:10\"}","Parent IDs":[1],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824870000\",\"name\":\"kafka direct stream [0]\\n@ 19:21:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824870000\",\"name\":\"map @ 19:21:10\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824870000\",\"name\":\"foreachRDD @ 19:21:10\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824870000"}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Launch Time":1448824870364,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Launch Time":1448824870364,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824872615,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":1967,"Executor Run Time":202,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":2,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824870000\",\"name\":\"filter @ 19:21:10\"}","Parent IDs":[1],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824870000\",\"name\":\"kafka direct stream [0]\\n@ 19:21:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824870000\",\"name\":\"map @ 19:21:10\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824870360,"Completion Time":1448824872622,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":0,"Completion Time":1448824872626,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":1,"Submission Time":1448824880033,"Stage Infos":[{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":5,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824880000\",\"name\":\"filter @ 19:21:20\"}","Parent IDs":[4],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":3,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824880000\",\"name\":\"kafka direct stream [0]\\n@ 19:21:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":4,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824880000\",\"name\":\"map @ 19:21:20\"}","Parent IDs":[3],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[1],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824880000\",\"name\":\"foreachRDD @ 19:21:20\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824880000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":5,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824880000\",\"name\":\"filter @ 19:21:20\"}","Parent IDs":[4],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":3,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824880000\",\"name\":\"kafka direct stream [0]\\n@ 19:21:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":4,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824880000\",\"name\":\"map @ 19:21:20\"}","Parent IDs":[3],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824880000\",\"name\":\"foreachRDD @ 19:21:20\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824880000"}}
{"Event":"SparkListenerTaskStart","Stage ID":1,"Stage Attempt ID":0,"Task Info":{"Task ID":1,"Index":0,"Attempt":0,"Launch Time":1448824880048,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":1,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":1,"Index":0,"Attempt":0,"Launch Time":1448824880048,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824880112,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":27,"Executor Run Time":21,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":5,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824880000\",\"name\":\"filter @ 19:21:20\"}","Parent IDs":[4],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":3,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824880000\",\"name\":\"kafka direct stream [0]\\n@ 19:21:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":4,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824880000\",\"name\":\"map @ 19:21:20\"}","Parent IDs":[3],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824880047,"Completion Time":1448824880113,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":1,"Completion Time":1448824880114,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":2}
{"Event":"SparkListenerUnpersistRDD","RDD ID":1}
{"Event":"SparkListenerUnpersistRDD","RDD ID":0}
{"Event":"SparkListenerJobStart","Job ID":2,"Submission Time":1448824890039,"Stage Infos":[{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":8,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824890000\",\"name\":\"filter @ 19:21:30\"}","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":6,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824890000\",\"name\":\"kafka direct stream [0]\\n@ 19:21:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824890000\",\"name\":\"map @ 19:21:30\"}","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[2],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824890000\",\"name\":\"foreachRDD @ 19:21:30\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824890000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":8,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824890000\",\"name\":\"filter @ 19:21:30\"}","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":6,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824890000\",\"name\":\"kafka direct stream [0]\\n@ 19:21:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824890000\",\"name\":\"map @ 19:21:30\"}","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824890000\",\"name\":\"foreachRDD @ 19:21:30\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824890000"}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":2,"Index":0,"Attempt":0,"Launch Time":1448824890061,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":2,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":2,"Index":0,"Attempt":0,"Launch Time":1448824890061,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824892340,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.36","Executor Deserialize Time":2029,"Executor Run Time":199,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":8,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824890000\",\"name\":\"filter @ 19:21:30\"}","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":6,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824890000\",\"name\":\"kafka direct stream [0]\\n@ 19:21:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824890000\",\"name\":\"map @ 19:21:30\"}","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824890060,"Completion Time":1448824892341,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":2,"Completion Time":1448824892341,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":5}
{"Event":"SparkListenerUnpersistRDD","RDD ID":4}
{"Event":"SparkListenerUnpersistRDD","RDD ID":3}
{"Event":"SparkListenerJobStart","Job ID":3,"Submission Time":1448824900038,"Stage Infos":[{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":11,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824900000\",\"name\":\"filter @ 19:21:40\"}","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":10,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824900000\",\"name\":\"map @ 19:21:40\"}","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":9,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824900000\",\"name\":\"kafka direct stream [0]\\n@ 19:21:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[3],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824900000\",\"name\":\"foreachRDD @ 19:21:40\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824900000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":11,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824900000\",\"name\":\"filter @ 19:21:40\"}","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":10,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824900000\",\"name\":\"map @ 19:21:40\"}","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":9,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824900000\",\"name\":\"kafka direct stream [0]\\n@ 19:21:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824900000\",\"name\":\"foreachRDD @ 19:21:40\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824900000"}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":3,"Index":0,"Attempt":0,"Launch Time":1448824900062,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":3,"Index":0,"Attempt":0,"Launch Time":1448824900062,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824900165,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.36","Executor Deserialize Time":47,"Executor Run Time":35,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":11,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824900000\",\"name\":\"filter @ 19:21:40\"}","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":10,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824900000\",\"name\":\"map @ 19:21:40\"}","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":9,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824900000\",\"name\":\"kafka direct stream [0]\\n@ 19:21:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824900061,"Completion Time":1448824900166,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":3,"Completion Time":1448824900166,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":8}
{"Event":"SparkListenerUnpersistRDD","RDD ID":7}
{"Event":"SparkListenerUnpersistRDD","RDD ID":6}
{"Event":"SparkListenerJobStart","Job ID":4,"Submission Time":1448824910039,"Stage Infos":[{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":14,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824910000\",\"name\":\"filter @ 19:21:50\"}","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824910000\",\"name\":\"map @ 19:21:50\"}","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":12,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824910000\",\"name\":\"kafka direct stream [0]\\n@ 19:21:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[4],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824910000\",\"name\":\"foreachRDD @ 19:21:50\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824910000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":14,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824910000\",\"name\":\"filter @ 19:21:50\"}","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824910000\",\"name\":\"map @ 19:21:50\"}","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":12,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824910000\",\"name\":\"kafka direct stream [0]\\n@ 19:21:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824910000\",\"name\":\"foreachRDD @ 19:21:50\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824910000"}}
{"Event":"SparkListenerTaskStart","Stage ID":4,"Stage Attempt ID":0,"Task Info":{"Task ID":4,"Index":0,"Attempt":0,"Launch Time":1448824910063,"Executor ID":"0","Host":"10.0.1.37","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":4,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":4,"Index":0,"Attempt":0,"Launch Time":1448824910063,"Executor ID":"0","Host":"10.0.1.37","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824912364,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.37","Executor Deserialize Time":2044,"Executor Run Time":215,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":14,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824910000\",\"name\":\"filter @ 19:21:50\"}","Parent IDs":[13],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824910000\",\"name\":\"map @ 19:21:50\"}","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":12,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824910000\",\"name\":\"kafka direct stream [0]\\n@ 19:21:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824910062,"Completion Time":1448824912365,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":4,"Completion Time":1448824912365,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":11}
{"Event":"SparkListenerUnpersistRDD","RDD ID":10}
{"Event":"SparkListenerUnpersistRDD","RDD ID":9}
{"Event":"SparkListenerJobStart","Job ID":5,"Submission Time":1448824920038,"Stage Infos":[{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":17,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824920000\",\"name\":\"filter @ 19:22:00\"}","Parent IDs":[16],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":16,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824920000\",\"name\":\"map @ 19:22:00\"}","Parent IDs":[15],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":15,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824920000\",\"name\":\"kafka direct stream [0]\\n@ 19:22:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[5],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824920000\",\"name\":\"foreachRDD @ 19:22:00\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824920000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":17,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824920000\",\"name\":\"filter @ 19:22:00\"}","Parent IDs":[16],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":16,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824920000\",\"name\":\"map @ 19:22:00\"}","Parent IDs":[15],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":15,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824920000\",\"name\":\"kafka direct stream [0]\\n@ 19:22:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824920000\",\"name\":\"foreachRDD @ 19:22:00\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824920000"}}
{"Event":"SparkListenerTaskStart","Stage ID":5,"Stage Attempt ID":0,"Task Info":{"Task ID":5,"Index":0,"Attempt":0,"Launch Time":1448824920057,"Executor ID":"3","Host":"10.0.1.38","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":5,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":5,"Index":0,"Attempt":0,"Launch Time":1448824920057,"Executor ID":"3","Host":"10.0.1.38","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824935306,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.38","Executor Deserialize Time":14949,"Executor Run Time":240,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":3,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":17,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824920000\",\"name\":\"filter @ 19:22:00\"}","Parent IDs":[16],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":16,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824920000\",\"name\":\"map @ 19:22:00\"}","Parent IDs":[15],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":15,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824920000\",\"name\":\"kafka direct stream [0]\\n@ 19:22:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824920057,"Completion Time":1448824935307,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":5,"Completion Time":1448824935307,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":6,"Submission Time":1448824935319,"Stage Infos":[{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":20,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824930000\",\"name\":\"filter @ 19:22:10\"}","Parent IDs":[19],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":18,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824930000\",\"name\":\"kafka direct stream [0]\\n@ 19:22:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824930000\",\"name\":\"map @ 19:22:10\"}","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[6],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824930000\",\"name\":\"foreachRDD @ 19:22:10\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824930000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":20,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824930000\",\"name\":\"filter @ 19:22:10\"}","Parent IDs":[19],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":18,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824930000\",\"name\":\"kafka direct stream [0]\\n@ 19:22:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824930000\",\"name\":\"map @ 19:22:10\"}","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824930000\",\"name\":\"foreachRDD @ 19:22:10\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824930000"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":14}
{"Event":"SparkListenerUnpersistRDD","RDD ID":13}
{"Event":"SparkListenerUnpersistRDD","RDD ID":12}
{"Event":"SparkListenerTaskStart","Stage ID":6,"Stage Attempt ID":0,"Task Info":{"Task ID":6,"Index":0,"Attempt":0,"Launch Time":1448824935340,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":6,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":6,"Index":0,"Attempt":0,"Launch Time":1448824935340,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824935406,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":31,"Executor Run Time":24,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":20,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824930000\",\"name\":\"filter @ 19:22:10\"}","Parent IDs":[19],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":18,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824930000\",\"name\":\"kafka direct stream [0]\\n@ 19:22:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824930000\",\"name\":\"map @ 19:22:10\"}","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824935339,"Completion Time":1448824935409,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":6,"Completion Time":1448824935409,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":17}
{"Event":"SparkListenerUnpersistRDD","RDD ID":16}
{"Event":"SparkListenerUnpersistRDD","RDD ID":15}
{"Event":"SparkListenerJobStart","Job ID":7,"Submission Time":1448824940035,"Stage Infos":[{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824940000\",\"name\":\"filter @ 19:22:20\"}","Parent IDs":[22],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":21,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824940000\",\"name\":\"kafka direct stream [0]\\n@ 19:22:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":22,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824940000\",\"name\":\"map @ 19:22:20\"}","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[7],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824940000\",\"name\":\"foreachRDD @ 19:22:20\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824940000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824940000\",\"name\":\"filter @ 19:22:20\"}","Parent IDs":[22],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":21,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824940000\",\"name\":\"kafka direct stream [0]\\n@ 19:22:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":22,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824940000\",\"name\":\"map @ 19:22:20\"}","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824940000\",\"name\":\"foreachRDD @ 19:22:20\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824940000"}}
{"Event":"SparkListenerTaskStart","Stage ID":7,"Stage Attempt ID":0,"Task Info":{"Task ID":7,"Index":0,"Attempt":0,"Launch Time":1448824940055,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":7,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":7,"Index":0,"Attempt":0,"Launch Time":1448824940055,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824940166,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.36","Executor Deserialize Time":50,"Executor Run Time":38,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824940000\",\"name\":\"filter @ 19:22:20\"}","Parent IDs":[22],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":21,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824940000\",\"name\":\"kafka direct stream [0]\\n@ 19:22:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":22,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824940000\",\"name\":\"map @ 19:22:20\"}","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824940054,"Completion Time":1448824940167,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":7,"Completion Time":1448824940167,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":20}
{"Event":"SparkListenerUnpersistRDD","RDD ID":19}
{"Event":"SparkListenerUnpersistRDD","RDD ID":18}
{"Event":"SparkListenerJobStart","Job ID":8,"Submission Time":1448824950031,"Stage Infos":[{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":26,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824950000\",\"name\":\"filter @ 19:22:30\"}","Parent IDs":[25],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":24,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824950000\",\"name\":\"kafka direct stream [0]\\n@ 19:22:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":25,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824950000\",\"name\":\"map @ 19:22:30\"}","Parent IDs":[24],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[8],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824950000\",\"name\":\"foreachRDD @ 19:22:30\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824950000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":26,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824950000\",\"name\":\"filter @ 19:22:30\"}","Parent IDs":[25],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":24,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824950000\",\"name\":\"kafka direct stream [0]\\n@ 19:22:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":25,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824950000\",\"name\":\"map @ 19:22:30\"}","Parent IDs":[24],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824950000\",\"name\":\"foreachRDD @ 19:22:30\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824950000"}}
{"Event":"SparkListenerTaskStart","Stage ID":8,"Stage Attempt ID":0,"Task Info":{"Task ID":8,"Index":0,"Attempt":0,"Launch Time":1448824950050,"Executor ID":"3","Host":"10.0.1.38","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":8,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":8,"Index":0,"Attempt":0,"Launch Time":1448824950050,"Executor ID":"3","Host":"10.0.1.38","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824950140,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.38","Executor Deserialize Time":39,"Executor Run Time":32,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":26,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824950000\",\"name\":\"filter @ 19:22:30\"}","Parent IDs":[25],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":24,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824950000\",\"name\":\"kafka direct stream [0]\\n@ 19:22:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":25,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824950000\",\"name\":\"map @ 19:22:30\"}","Parent IDs":[24],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824950052,"Completion Time":1448824950140,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":8,"Completion Time":1448824950140,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":23}
{"Event":"SparkListenerUnpersistRDD","RDD ID":22}
{"Event":"SparkListenerUnpersistRDD","RDD ID":21}
{"Event":"SparkListenerJobStart","Job ID":9,"Submission Time":1448824960032,"Stage Infos":[{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":29,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824960000\",\"name\":\"filter @ 19:22:40\"}","Parent IDs":[28],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":27,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824960000\",\"name\":\"kafka direct stream [0]\\n@ 19:22:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":28,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824960000\",\"name\":\"map @ 19:22:40\"}","Parent IDs":[27],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[9],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824960000\",\"name\":\"foreachRDD @ 19:22:40\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824960000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":29,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824960000\",\"name\":\"filter @ 19:22:40\"}","Parent IDs":[28],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":27,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824960000\",\"name\":\"kafka direct stream [0]\\n@ 19:22:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":28,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824960000\",\"name\":\"map @ 19:22:40\"}","Parent IDs":[27],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824960000\",\"name\":\"foreachRDD @ 19:22:40\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824960000"}}
{"Event":"SparkListenerTaskStart","Stage ID":9,"Stage Attempt ID":0,"Task Info":{"Task ID":9,"Index":0,"Attempt":0,"Launch Time":1448824960053,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":9,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":9,"Index":0,"Attempt":0,"Launch Time":1448824960053,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824960120,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":31,"Executor Run Time":21,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":29,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824960000\",\"name\":\"filter @ 19:22:40\"}","Parent IDs":[28],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":27,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824960000\",\"name\":\"kafka direct stream [0]\\n@ 19:22:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":28,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824960000\",\"name\":\"map @ 19:22:40\"}","Parent IDs":[27],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824960052,"Completion Time":1448824960120,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":9,"Completion Time":1448824960120,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":26}
{"Event":"SparkListenerUnpersistRDD","RDD ID":25}
{"Event":"SparkListenerUnpersistRDD","RDD ID":24}
{"Event":"SparkListenerJobStart","Job ID":10,"Submission Time":1448824970033,"Stage Infos":[{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":32,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824970000\",\"name\":\"filter @ 19:22:50\"}","Parent IDs":[31],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":30,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824970000\",\"name\":\"kafka direct stream [0]\\n@ 19:22:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":31,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824970000\",\"name\":\"map @ 19:22:50\"}","Parent IDs":[30],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[10],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824970000\",\"name\":\"foreachRDD @ 19:22:50\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824970000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":32,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824970000\",\"name\":\"filter @ 19:22:50\"}","Parent IDs":[31],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":30,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824970000\",\"name\":\"kafka direct stream [0]\\n@ 19:22:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":31,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824970000\",\"name\":\"map @ 19:22:50\"}","Parent IDs":[30],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824970000\",\"name\":\"foreachRDD @ 19:22:50\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824970000"}}
{"Event":"SparkListenerTaskStart","Stage ID":10,"Stage Attempt ID":0,"Task Info":{"Task ID":10,"Index":0,"Attempt":0,"Launch Time":1448824970052,"Executor ID":"0","Host":"10.0.1.37","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":10,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":10,"Index":0,"Attempt":0,"Launch Time":1448824970052,"Executor ID":"0","Host":"10.0.1.37","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824970152,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.37","Executor Deserialize Time":35,"Executor Run Time":47,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":32,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824970000\",\"name\":\"filter @ 19:22:50\"}","Parent IDs":[31],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":30,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824970000\",\"name\":\"kafka direct stream [0]\\n@ 19:22:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":31,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824970000\",\"name\":\"map @ 19:22:50\"}","Parent IDs":[30],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824970052,"Completion Time":1448824970153,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":10,"Completion Time":1448824970153,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":29}
{"Event":"SparkListenerUnpersistRDD","RDD ID":28}
{"Event":"SparkListenerUnpersistRDD","RDD ID":27}
{"Event":"SparkListenerJobStart","Job ID":11,"Submission Time":1448824980033,"Stage Infos":[{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":35,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824980000\",\"name\":\"filter @ 19:23:00\"}","Parent IDs":[34],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":34,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824980000\",\"name\":\"map @ 19:23:00\"}","Parent IDs":[33],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":33,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824980000\",\"name\":\"kafka direct stream [0]\\n@ 19:23:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[11],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824980000\",\"name\":\"foreachRDD @ 19:23:00\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824980000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":35,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824980000\",\"name\":\"filter @ 19:23:00\"}","Parent IDs":[34],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":34,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824980000\",\"name\":\"map @ 19:23:00\"}","Parent IDs":[33],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":33,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824980000\",\"name\":\"kafka direct stream [0]\\n@ 19:23:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824980000\",\"name\":\"foreachRDD @ 19:23:00\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824980000"}}
{"Event":"SparkListenerTaskStart","Stage ID":11,"Stage Attempt ID":0,"Task Info":{"Task ID":11,"Index":0,"Attempt":0,"Launch Time":1448824980060,"Executor ID":"0","Host":"10.0.1.37","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":11,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":11,"Index":0,"Attempt":0,"Launch Time":1448824980060,"Executor ID":"0","Host":"10.0.1.37","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824980145,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.37","Executor Deserialize Time":31,"Executor Run Time":39,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":35,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824980000\",\"name\":\"filter @ 19:23:00\"}","Parent IDs":[34],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":34,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824980000\",\"name\":\"map @ 19:23:00\"}","Parent IDs":[33],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":33,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824980000\",\"name\":\"kafka direct stream [0]\\n@ 19:23:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824980059,"Completion Time":1448824980145,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":11,"Completion Time":1448824980145,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":32}
{"Event":"SparkListenerUnpersistRDD","RDD ID":31}
{"Event":"SparkListenerUnpersistRDD","RDD ID":30}
{"Event":"SparkListenerJobStart","Job ID":12,"Submission Time":1448824990029,"Stage Infos":[{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":38,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824990000\",\"name\":\"filter @ 19:23:10\"}","Parent IDs":[37],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":36,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824990000\",\"name\":\"kafka direct stream [0]\\n@ 19:23:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":37,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824990000\",\"name\":\"map @ 19:23:10\"}","Parent IDs":[36],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[12],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824990000\",\"name\":\"foreachRDD @ 19:23:10\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824990000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":38,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824990000\",\"name\":\"filter @ 19:23:10\"}","Parent IDs":[37],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":36,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824990000\",\"name\":\"kafka direct stream [0]\\n@ 19:23:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":37,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824990000\",\"name\":\"map @ 19:23:10\"}","Parent IDs":[36],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448824990000\",\"name\":\"foreachRDD @ 19:23:10\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824990000"}}
{"Event":"SparkListenerTaskStart","Stage ID":12,"Stage Attempt ID":0,"Task Info":{"Task ID":12,"Index":0,"Attempt":0,"Launch Time":1448824990049,"Executor ID":"0","Host":"10.0.1.37","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":12,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":12,"Index":0,"Attempt":0,"Launch Time":1448824990049,"Executor ID":"0","Host":"10.0.1.37","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824990140,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.37","Executor Deserialize Time":34,"Executor Run Time":40,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":38,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824990000\",\"name\":\"filter @ 19:23:10\"}","Parent IDs":[37],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":36,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824990000\",\"name\":\"kafka direct stream [0]\\n@ 19:23:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":37,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824990000\",\"name\":\"map @ 19:23:10\"}","Parent IDs":[36],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824990048,"Completion Time":1448824990140,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":12,"Completion Time":1448824990141,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":35}
{"Event":"SparkListenerUnpersistRDD","RDD ID":34}
{"Event":"SparkListenerUnpersistRDD","RDD ID":33}
{"Event":"SparkListenerJobStart","Job ID":13,"Submission Time":1448825000033,"Stage Infos":[{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825000000\",\"name\":\"filter @ 19:23:20\"}","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":39,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825000000\",\"name\":\"kafka direct stream [0]\\n@ 19:23:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":40,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825000000\",\"name\":\"map @ 19:23:20\"}","Parent IDs":[39],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[13],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448825000000\",\"name\":\"foreachRDD @ 19:23:20\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448825000000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825000000\",\"name\":\"filter @ 19:23:20\"}","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":39,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825000000\",\"name\":\"kafka direct stream [0]\\n@ 19:23:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":40,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825000000\",\"name\":\"map @ 19:23:20\"}","Parent IDs":[39],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448825000000\",\"name\":\"foreachRDD @ 19:23:20\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448825000000"}}
{"Event":"SparkListenerTaskStart","Stage ID":13,"Stage Attempt ID":0,"Task Info":{"Task ID":13,"Index":0,"Attempt":0,"Launch Time":1448825000052,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":13,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":13,"Index":0,"Attempt":0,"Launch Time":1448825000052,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448825000118,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":32,"Executor Run Time":19,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825000000\",\"name\":\"filter @ 19:23:20\"}","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":39,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825000000\",\"name\":\"kafka direct stream [0]\\n@ 19:23:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":40,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825000000\",\"name\":\"map @ 19:23:20\"}","Parent IDs":[39],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448825000051,"Completion Time":1448825000119,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":13,"Completion Time":1448825000119,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":38}
{"Event":"SparkListenerUnpersistRDD","RDD ID":37}
{"Event":"SparkListenerUnpersistRDD","RDD ID":36}
{"Event":"SparkListenerJobStart","Job ID":14,"Submission Time":1448825010034,"Stage Infos":[{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":44,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825010000\",\"name\":\"filter @ 19:23:30\"}","Parent IDs":[43],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825010000\",\"name\":\"map @ 19:23:30\"}","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":42,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825010000\",\"name\":\"kafka direct stream [0]\\n@ 19:23:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[14],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448825010000\",\"name\":\"foreachRDD @ 19:23:30\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448825010000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":44,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825010000\",\"name\":\"filter @ 19:23:30\"}","Parent IDs":[43],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825010000\",\"name\":\"map @ 19:23:30\"}","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":42,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825010000\",\"name\":\"kafka direct stream [0]\\n@ 19:23:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448825010000\",\"name\":\"foreachRDD @ 19:23:30\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448825010000"}}
{"Event":"SparkListenerTaskStart","Stage ID":14,"Stage Attempt ID":0,"Task Info":{"Task ID":14,"Index":0,"Attempt":0,"Launch Time":1448825010054,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":14,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":14,"Index":0,"Attempt":0,"Launch Time":1448825010054,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448825010123,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":32,"Executor Run Time":21,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":44,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825010000\",\"name\":\"filter @ 19:23:30\"}","Parent IDs":[43],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825010000\",\"name\":\"map @ 19:23:30\"}","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":42,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825010000\",\"name\":\"kafka direct stream [0]\\n@ 19:23:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448825010053,"Completion Time":1448825010124,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":14,"Completion Time":1448825010124,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":41}
{"Event":"SparkListenerUnpersistRDD","RDD ID":40}
{"Event":"SparkListenerUnpersistRDD","RDD ID":39}
{"Event":"SparkListenerJobStart","Job ID":15,"Submission Time":1448825020035,"Stage Infos":[{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":47,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825020000\",\"name\":\"filter @ 19:23:40\"}","Parent IDs":[46],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825020000\",\"name\":\"map @ 19:23:40\"}","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":45,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825020000\",\"name\":\"kafka direct stream [0]\\n@ 19:23:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[15],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448825020000\",\"name\":\"foreachRDD @ 19:23:40\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448825020000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":47,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825020000\",\"name\":\"filter @ 19:23:40\"}","Parent IDs":[46],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825020000\",\"name\":\"map @ 19:23:40\"}","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":45,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825020000\",\"name\":\"kafka direct stream [0]\\n@ 19:23:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448825020000\",\"name\":\"foreachRDD @ 19:23:40\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448825020000"}}
{"Event":"SparkListenerTaskStart","Stage ID":15,"Stage Attempt ID":0,"Task Info":{"Task ID":15,"Index":0,"Attempt":0,"Launch Time":1448825020058,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":15,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":15,"Index":0,"Attempt":0,"Launch Time":1448825020058,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448825020175,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.36","Executor Deserialize Time":48,"Executor Run Time":42,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":47,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825020000\",\"name\":\"filter @ 19:23:40\"}","Parent IDs":[46],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825020000\",\"name\":\"map @ 19:23:40\"}","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":45,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825020000\",\"name\":\"kafka direct stream [0]\\n@ 19:23:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448825020057,"Completion Time":1448825020176,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":15,"Completion Time":1448825020176,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":44}
{"Event":"SparkListenerUnpersistRDD","RDD ID":43}
{"Event":"SparkListenerUnpersistRDD","RDD ID":42}
{"Event":"SparkListenerJobStart","Job ID":16,"Submission Time":1448825030031,"Stage Infos":[{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":50,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825030000\",\"name\":\"filter @ 19:23:50\"}","Parent IDs":[49],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":48,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825030000\",\"name\":\"kafka direct stream [0]\\n@ 19:23:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825030000\",\"name\":\"map @ 19:23:50\"}","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[16],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448825030000\",\"name\":\"foreachRDD @ 19:23:50\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448825030000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":50,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825030000\",\"name\":\"filter @ 19:23:50\"}","Parent IDs":[49],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":48,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825030000\",\"name\":\"kafka direct stream [0]\\n@ 19:23:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825030000\",\"name\":\"map @ 19:23:50\"}","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448825030000\",\"name\":\"foreachRDD @ 19:23:50\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448825030000"}}
{"Event":"SparkListenerTaskStart","Stage ID":16,"Stage Attempt ID":0,"Task Info":{"Task ID":16,"Index":0,"Attempt":0,"Launch Time":1448825030049,"Executor ID":"0","Host":"10.0.1.37","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":16,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":16,"Index":0,"Attempt":0,"Launch Time":1448825030049,"Executor ID":"0","Host":"10.0.1.37","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448825030140,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.37","Executor Deserialize Time":32,"Executor Run Time":43,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":50,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825030000\",\"name\":\"filter @ 19:23:50\"}","Parent IDs":[49],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":48,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825030000\",\"name\":\"kafka direct stream [0]\\n@ 19:23:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825030000\",\"name\":\"map @ 19:23:50\"}","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448825030049,"Completion Time":1448825030141,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":16,"Completion Time":1448825030141,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":47}
{"Event":"SparkListenerUnpersistRDD","RDD ID":46}
{"Event":"SparkListenerUnpersistRDD","RDD ID":45}
{"Event":"SparkListenerJobStart","Job ID":17,"Submission Time":1448825040030,"Stage Infos":[{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":53,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825040000\",\"name\":\"filter @ 19:24:00\"}","Parent IDs":[52],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":51,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825040000\",\"name\":\"kafka direct stream [0]\\n@ 19:24:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":52,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825040000\",\"name\":\"map @ 19:24:00\"}","Parent IDs":[51],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[17],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448825040000\",\"name\":\"foreachRDD @ 19:24:00\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448825040000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":53,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825040000\",\"name\":\"filter @ 19:24:00\"}","Parent IDs":[52],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":51,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825040000\",\"name\":\"kafka direct stream [0]\\n@ 19:24:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":52,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825040000\",\"name\":\"map @ 19:24:00\"}","Parent IDs":[51],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448825040000\",\"name\":\"foreachRDD @ 19:24:00\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448825040000"}}
{"Event":"SparkListenerTaskStart","Stage ID":17,"Stage Attempt ID":0,"Task Info":{"Task ID":17,"Index":0,"Attempt":0,"Launch Time":1448825040048,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":17,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":17,"Index":0,"Attempt":0,"Launch Time":1448825040048,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448825040118,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":34,"Executor Run Time":22,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":53,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825040000\",\"name\":\"filter @ 19:24:00\"}","Parent IDs":[52],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":51,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825040000\",\"name\":\"kafka direct stream [0]\\n@ 19:24:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":52,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825040000\",\"name\":\"map @ 19:24:00\"}","Parent IDs":[51],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448825040047,"Completion Time":1448825040121,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":17,"Completion Time":1448825040121,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":50}
{"Event":"SparkListenerUnpersistRDD","RDD ID":49}
{"Event":"SparkListenerUnpersistRDD","RDD ID":48}
{"Event":"SparkListenerJobStart","Job ID":18,"Submission Time":1448825050032,"Stage Infos":[{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":56,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825050000\",\"name\":\"filter @ 19:24:10\"}","Parent IDs":[55],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":54,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825050000\",\"name\":\"kafka direct stream [0]\\n@ 19:24:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":55,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825050000\",\"name\":\"map @ 19:24:10\"}","Parent IDs":[54],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[18],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448825050000\",\"name\":\"foreachRDD @ 19:24:10\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448825050000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":56,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825050000\",\"name\":\"filter @ 19:24:10\"}","Parent IDs":[55],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":54,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825050000\",\"name\":\"kafka direct stream [0]\\n@ 19:24:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":55,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825050000\",\"name\":\"map @ 19:24:10\"}","Parent IDs":[54],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448825050000\",\"name\":\"foreachRDD @ 19:24:10\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448825050000"}}
{"Event":"SparkListenerTaskStart","Stage ID":18,"Stage Attempt ID":0,"Task Info":{"Task ID":18,"Index":0,"Attempt":0,"Launch Time":1448825050049,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":18,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":18,"Index":0,"Attempt":0,"Launch Time":1448825050049,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448825050113,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":30,"Executor Run Time":18,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":56,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825050000\",\"name\":\"filter @ 19:24:10\"}","Parent IDs":[55],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":54,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825050000\",\"name\":\"kafka direct stream [0]\\n@ 19:24:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":55,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825050000\",\"name\":\"map @ 19:24:10\"}","Parent IDs":[54],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448825050048,"Completion Time":1448825050114,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":18,"Completion Time":1448825050114,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":53}
{"Event":"SparkListenerUnpersistRDD","RDD ID":52}
{"Event":"SparkListenerUnpersistRDD","RDD ID":51}
{"Event":"SparkListenerJobStart","Job ID":19,"Submission Time":1448825060038,"Stage Infos":[{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":59,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825060000\",\"name\":\"filter @ 19:24:20\"}","Parent IDs":[58],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":58,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825060000\",\"name\":\"map @ 19:24:20\"}","Parent IDs":[57],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":57,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825060000\",\"name\":\"kafka direct stream [0]\\n@ 19:24:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[19],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448825060000\",\"name\":\"foreachRDD @ 19:24:20\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448825060000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":59,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825060000\",\"name\":\"filter @ 19:24:20\"}","Parent IDs":[58],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":58,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825060000\",\"name\":\"map @ 19:24:20\"}","Parent IDs":[57],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":57,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825060000\",\"name\":\"kafka direct stream [0]\\n@ 19:24:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448825060000\",\"name\":\"foreachRDD @ 19:24:20\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448825060000"}}
{"Event":"SparkListenerTaskStart","Stage ID":19,"Stage Attempt ID":0,"Task Info":{"Task ID":19,"Index":0,"Attempt":0,"Launch Time":1448825060055,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":19,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":19,"Index":0,"Attempt":0,"Launch Time":1448825060055,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448825060814,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.36","Executor Deserialize Time":44,"Executor Run Time":694,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":59,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825060000\",\"name\":\"filter @ 19:24:20\"}","Parent IDs":[58],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":58,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825060000\",\"name\":\"map @ 19:24:20\"}","Parent IDs":[57],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":57,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825060000\",\"name\":\"kafka direct stream [0]\\n@ 19:24:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448825060055,"Completion Time":1448825060814,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":19,"Completion Time":1448825060815,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":56}
{"Event":"SparkListenerUnpersistRDD","RDD ID":55}
{"Event":"SparkListenerUnpersistRDD","RDD ID":54}
{"Event":"SparkListenerJobStart","Job ID":20,"Submission Time":1448825070039,"Stage Infos":[{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":62,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825070000\",\"name\":\"filter @ 19:24:30\"}","Parent IDs":[61],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":61,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825070000\",\"name\":\"map @ 19:24:30\"}","Parent IDs":[60],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":60,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825070000\",\"name\":\"kafka direct stream [0]\\n@ 19:24:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[20],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448825070000\",\"name\":\"foreachRDD @ 19:24:30\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448825070000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":62,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825070000\",\"name\":\"filter @ 19:24:30\"}","Parent IDs":[61],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":61,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825070000\",\"name\":\"map @ 19:24:30\"}","Parent IDs":[60],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":60,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825070000\",\"name\":\"kafka direct stream [0]\\n@ 19:24:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448825070000\",\"name\":\"foreachRDD @ 19:24:30\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448825070000"}}
{"Event":"SparkListenerTaskStart","Stage ID":20,"Stage Attempt ID":0,"Task Info":{"Task ID":20,"Index":0,"Attempt":0,"Launch Time":1448825070055,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":20,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":20,"Index":0,"Attempt":0,"Launch Time":1448825070055,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448825070108,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":31,"Executor Run Time":2,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":62,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825070000\",\"name\":\"filter @ 19:24:30\"}","Parent IDs":[61],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":61,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825070000\",\"name\":\"map @ 19:24:30\"}","Parent IDs":[60],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":60,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825070000\",\"name\":\"kafka direct stream [0]\\n@ 19:24:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448825070055,"Completion Time":1448825070108,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":20,"Completion Time":1448825070108,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":59}
{"Event":"SparkListenerUnpersistRDD","RDD ID":58}
{"Event":"SparkListenerUnpersistRDD","RDD ID":57}
{"Event":"SparkListenerJobStart","Job ID":21,"Submission Time":1448825080031,"Stage Infos":[{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":65,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825080000\",\"name\":\"filter @ 19:24:40\"}","Parent IDs":[64],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":63,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825080000\",\"name\":\"kafka direct stream [0]\\n@ 19:24:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":64,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825080000\",\"name\":\"map @ 19:24:40\"}","Parent IDs":[63],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[21],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448825080000\",\"name\":\"foreachRDD @ 19:24:40\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448825080000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":65,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825080000\",\"name\":\"filter @ 19:24:40\"}","Parent IDs":[64],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":63,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825080000\",\"name\":\"kafka direct stream [0]\\n@ 19:24:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":64,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825080000\",\"name\":\"map @ 19:24:40\"}","Parent IDs":[63],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"3_1448825080000\",\"name\":\"foreachRDD @ 19:24:40\"}","callSite.short":"foreachRDD at GrepStreamJob.scala:35","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448825080000"}}
{"Event":"SparkListenerTaskStart","Stage ID":21,"Stage Attempt ID":0,"Task Info":{"Task ID":21,"Index":0,"Attempt":0,"Launch Time":1448825080045,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":21,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":21,"Index":0,"Attempt":0,"Launch Time":1448825080045,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448825080095,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.36","Executor Deserialize Time":33,"Executor Run Time":2,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"foreachRDD at GrepStreamJob.scala:35","Number of Tasks":1,"RDD Info":[{"RDD ID":65,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448825080000\",\"name\":\"filter @ 19:24:40\"}","Parent IDs":[64],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":63,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448825080000\",\"name\":\"kafka direct stream [0]\\n@ 19:24:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":64,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448825080000\",\"name\":\"map @ 19:24:40\"}","Parent IDs":[63],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.GrepStreamJob.processStreamData(GrepStreamJob.scala:35)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:76)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448825080045,"Completion Time":1448825080096,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":21,"Completion Time":1448825080096,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":62}
{"Event":"SparkListenerUnpersistRDD","RDD ID":61}
{"Event":"SparkListenerUnpersistRDD","RDD ID":60}
