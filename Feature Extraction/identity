{"Event":"SparkListenerLogStart","Spark Version":"1.5.0"}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"driver","Host":"10.0.1.35","Port":56434},"Maximum Memory":2223023063,"Timestamp":1448814565919}
{"Event":"SparkListenerEnvironmentUpdate","JVM Information":{"Java Home":"/usr/lib/jvm/java-7-openjdk-amd64/jre","Java Version":"1.7.0_85 (Oracle Corporation)","Scala Version":"version 2.10.4"},"Spark Properties":{"spark.akka.timeout":"600","spark.driver.host":"10.0.1.35","spark.kryoserializer.buffer.mb":"2000","spark.broadcast.compress":"false","spark.io.compression.codec":"org.apache.spark.io.SnappyCompressionCodec","spark.eventLog.enabled":"true","spark.driver.port":"50065","spark.rdd.compress":"false","spark.cleaner.ttl":"7200","spark.shuffle.compress":"false","spark.jars":"file:/home/ubuntu/software/HiBench-master/src/streambench/sparkbench/target/streaming-bench-spark_0.1-4.0-SNAPSHOT-jar-with-dependencies.jar,file:/home/ubuntu/software/HiBench-master/src/sparkbench/target/sparkbench-4.0-SNAPSHOT-MR2-spark1.5-jar-with-dependencies.jar","spark.app.name":"identity","spark.scheduler.mode":"FIFO","spark.driver.memory":"4G","spark.default.parallelism":"12","spark.executor.id":"driver","spark.submit.deployMode":"client","spark.master":"spark://10.0.1.35:7077","spark.executor.memory":"4G","spark.eventLog.dir":"/home/ubuntu","spark.fileserver.uri":"http://10.0.1.35:52064","spark.externalBlockStore.folderName":"spark-4e63c35a-a3b5-47d4-ae0a-10796f2e0539","spark.app.id":"app-20151129162925-0024","spark.akka.frameSize":"1000","spark.sql.shuffle.partitions":"12"},"System Properties":{"java.io.tmpdir":"/tmp","line.separator":"\n","path.separator":":","sun.management.compiler":"HotSpot 64-Bit Tiered Compilers","SPARK_SUBMIT":"true","sun.cpu.endian":"little","java.specification.version":"1.7","java.vm.specification.name":"Java Virtual Machine Specification","java.vendor":"Oracle Corporation","java.vm.specification.version":"1.7","user.home":"/home/ubuntu","file.encoding.pkg":"sun.io","sun.nio.ch.bugLevel":"","sun.arch.data.model":"64","sun.boot.library.path":"/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/amd64","user.dir":"/home/ubuntu/software/HiBench-master/workloads/streamingbench/spark/bin","java.library.path":"/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/native/::/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib","sun.cpu.isalist":"","os.arch":"amd64","java.vm.version":"24.85-b03","java.endorsed.dirs":"/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/endorsed","java.runtime.version":"1.7.0_85-b01","java.vm.info":"mixed mode","java.ext.dirs":"/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext","java.runtime.name":"OpenJDK Runtime Environment","file.separator":"/","java.class.version":"51.0","java.specification.name":"Java Platform API Specification","sun.boot.class.path":"/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/rhino.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/classes","file.encoding":"UTF-8","user.timezone":"Etc/UTC","java.specification.vendor":"Oracle Corporation","sun.java.launcher":"SUN_STANDARD","os.version":"3.13.0-46-generic","sun.os.patch.level":"unknown","java.vm.specification.vendor":"Oracle Corporation","user.country":"US","sun.jnu.encoding":"UTF-8","user.language":"en","java.vendor.url":"http://java.oracle.com/","java.awt.printerjob":"sun.print.PSPrinterJob","java.awt.graphicsenv":"sun.awt.X11GraphicsEnvironment","awt.toolkit":"sun.awt.X11.XToolkit","os.name":"Linux","java.vm.vendor":"Oracle Corporation","java.vendor.url.bug":"http://bugreport.sun.com/bugreport/","user.name":"ubuntu","java.vm.name":"OpenJDK 64-Bit Server VM","sun.java.command":"org.apache.spark.deploy.SparkSubmit --master spark://10.0.1.35:7077 --properties-file /home/ubuntu/software/HiBench-master/report/streamingbench/spark/conf/sparkbench/spark.conf --class com.intel.hibench.streambench.spark.RunBench --jars /home/ubuntu/software/HiBench-master/src/streambench/sparkbench/target/streaming-bench-spark_0.1-4.0-SNAPSHOT-jar-with-dependencies.jar /home/ubuntu/software/HiBench-master/src/sparkbench/target/sparkbench-4.0-SNAPSHOT-MR2-spark1.5-jar-with-dependencies.jar /home/ubuntu/software/HiBench-master/report/streamingbench/spark/conf/sparkbench/sparkbench.conf","java.home":"/usr/lib/jvm/java-7-openjdk-amd64/jre","java.version":"1.7.0_85","sun.io.unicode.encoding":"UnicodeLittle"},"Classpath Entries":{"/home/ubuntu/software/spark-1.5.0-bin-hadoop2.6/lib/datanucleus-api-jdo-3.2.6.jar":"System Classpath","http://10.0.1.35:52064/jars/streaming-bench-spark_0.1-4.0-SNAPSHOT-jar-with-dependencies.jar":"Added By User","/home/ubuntu/conf/":"System Classpath","/home/ubuntu/software/spark-1.5.0-bin-hadoop2.6/lib/datanucleus-rdbms-3.2.9.jar":"System Classpath","/home/ubuntu/software/spark-1.5.0-bin-hadoop2.6/lib/spark-assembly-1.5.0-hadoop2.6.0.jar":"System Classpath","/home/ubuntu/software/spark-1.5.0-bin-hadoop2.6/lib/datanucleus-core-3.2.10.jar":"System Classpath"}}
{"Event":"SparkListenerApplicationStart","App Name":"identity","App ID":"app-20151129162925-0024","Timestamp":1448814562524,"User":"ubuntu"}
{"Event":"SparkListenerExecutorAdded","Timestamp":1448814569102,"Executor ID":"2","Executor Info":{"Host":"10.0.1.36","Total Cores":5,"Log Urls":{"stdout":"http://10.0.1.36:8081/logPage/?appId=app-20151129162925-0024&executorId=2&logType=stdout","stderr":"http://10.0.1.36:8081/logPage/?appId=app-20151129162925-0024&executorId=2&logType=stderr"}}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1448814569116,"Executor ID":"1","Executor Info":{"Host":"10.0.1.35","Total Cores":5,"Log Urls":{"stdout":"http://10.0.1.35:8081/logPage/?appId=app-20151129162925-0024&executorId=1&logType=stdout","stderr":"http://10.0.1.35:8081/logPage/?appId=app-20151129162925-0024&executorId=1&logType=stderr"}}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1448814569162,"Executor ID":"3","Executor Info":{"Host":"10.0.1.38","Total Cores":5,"Log Urls":{"stdout":"http://10.0.1.38:8081/logPage/?appId=app-20151129162925-0024&executorId=3&logType=stdout","stderr":"http://10.0.1.38:8081/logPage/?appId=app-20151129162925-0024&executorId=3&logType=stderr"}}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1448814569229,"Executor ID":"0","Executor Info":{"Host":"10.0.1.37","Total Cores":5,"Log Urls":{"stdout":"http://10.0.1.37:8081/logPage/?appId=app-20151129162925-0024&executorId=0&logType=stdout","stderr":"http://10.0.1.37:8081/logPage/?appId=app-20151129162925-0024&executorId=0&logType=stderr"}}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"2","Host":"10.0.1.36","Port":46258},"Maximum Memory":2223023063,"Timestamp":1448814569311}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"1","Host":"10.0.1.35","Port":48989},"Maximum Memory":2223023063,"Timestamp":1448814569328}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"3","Host":"10.0.1.38","Port":49671},"Maximum Memory":2223023063,"Timestamp":1448814569371}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"0","Host":"10.0.1.37","Port":59520},"Maximum Memory":2223023063,"Timestamp":1448814569437}
{"Event":"SparkListenerJobStart","Job ID":0,"Submission Time":1448814570142,"Stage Infos":[{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814570000\",\"name\":\"map @ 16:29:30\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814570000\",\"name\":\"kafka direct stream [0]\\n@ 16:29:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[0],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448814570000\",\"name\":\"foreachRDD @ 16:29:30\"}","callSite.short":"foreachRDD at IdentityJob.scala:27","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448814570000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814570000\",\"name\":\"map @ 16:29:30\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814570000\",\"name\":\"kafka direct stream [0]\\n@ 16:29:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448814570000\",\"name\":\"foreachRDD @ 16:29:30\"}","callSite.short":"foreachRDD at IdentityJob.scala:27","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448814570000"}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Launch Time":1448814570293,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Launch Time":1448814570293,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448814575510,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":1882,"Executor Run Time":3252,"Result Size":915,"JVM GC Time":81,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814570000\",\"name\":\"map @ 16:29:30\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814570000\",\"name\":\"kafka direct stream [0]\\n@ 16:29:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448814570289,"Completion Time":1448814575520,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":0,"Completion Time":1448814575524,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":1,"Submission Time":1448814580040,"Stage Infos":[{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":3,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814580000\",\"name\":\"map @ 16:29:40\"}","Parent IDs":[2],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":2,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814580000\",\"name\":\"kafka direct stream [0]\\n@ 16:29:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[1],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448814580000\",\"name\":\"foreachRDD @ 16:29:40\"}","callSite.short":"foreachRDD at IdentityJob.scala:27","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448814580000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":3,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814580000\",\"name\":\"map @ 16:29:40\"}","Parent IDs":[2],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":2,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814580000\",\"name\":\"kafka direct stream [0]\\n@ 16:29:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448814580000\",\"name\":\"foreachRDD @ 16:29:40\"}","callSite.short":"foreachRDD at IdentityJob.scala:27","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448814580000"}}
{"Event":"SparkListenerTaskStart","Stage ID":1,"Stage Attempt ID":0,"Task Info":{"Task ID":1,"Index":0,"Attempt":0,"Launch Time":1448814580057,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":1,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":1,"Index":0,"Attempt":0,"Launch Time":1448814580057,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448814582382,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.36","Executor Deserialize Time":2068,"Executor Run Time":210,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":3,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814580000\",\"name\":\"map @ 16:29:40\"}","Parent IDs":[2],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":2,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814580000\",\"name\":\"kafka direct stream [0]\\n@ 16:29:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448814580057,"Completion Time":1448814582383,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":1,"Completion Time":1448814582383,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":1}
{"Event":"SparkListenerUnpersistRDD","RDD ID":0}
{"Event":"SparkListenerJobStart","Job ID":2,"Submission Time":1448814590032,"Stage Infos":[{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":5,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814590000\",\"name\":\"map @ 16:29:50\"}","Parent IDs":[4],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":4,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814590000\",\"name\":\"kafka direct stream [0]\\n@ 16:29:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[2],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448814590000\",\"name\":\"foreachRDD @ 16:29:50\"}","callSite.short":"foreachRDD at IdentityJob.scala:27","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448814590000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":5,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814590000\",\"name\":\"map @ 16:29:50\"}","Parent IDs":[4],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":4,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814590000\",\"name\":\"kafka direct stream [0]\\n@ 16:29:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448814590000\",\"name\":\"foreachRDD @ 16:29:50\"}","callSite.short":"foreachRDD at IdentityJob.scala:27","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448814590000"}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":2,"Index":0,"Attempt":0,"Launch Time":1448814590053,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":2,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":2,"Index":0,"Attempt":0,"Launch Time":1448814590053,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448814590124,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":31,"Executor Run Time":19,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":5,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814590000\",\"name\":\"map @ 16:29:50\"}","Parent IDs":[4],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":4,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814590000\",\"name\":\"kafka direct stream [0]\\n@ 16:29:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448814590053,"Completion Time":1448814590125,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":2,"Completion Time":1448814590125,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":3}
{"Event":"SparkListenerUnpersistRDD","RDD ID":2}
{"Event":"SparkListenerJobStart","Job ID":3,"Submission Time":1448814600039,"Stage Infos":[{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814600000\",\"name\":\"map @ 16:30:00\"}","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":6,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814600000\",\"name\":\"kafka direct stream [0]\\n@ 16:30:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[3],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448814600000\",\"name\":\"foreachRDD @ 16:30:00\"}","callSite.short":"foreachRDD at IdentityJob.scala:27","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448814600000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814600000\",\"name\":\"map @ 16:30:00\"}","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":6,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814600000\",\"name\":\"kafka direct stream [0]\\n@ 16:30:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448814600000\",\"name\":\"foreachRDD @ 16:30:00\"}","callSite.short":"foreachRDD at IdentityJob.scala:27","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448814600000"}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":3,"Index":0,"Attempt":0,"Launch Time":1448814600058,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":3,"Index":0,"Attempt":0,"Launch Time":1448814600058,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448814600121,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":31,"Executor Run Time":15,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814600000\",\"name\":\"map @ 16:30:00\"}","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":6,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814600000\",\"name\":\"kafka direct stream [0]\\n@ 16:30:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448814600058,"Completion Time":1448814600123,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":3,"Completion Time":1448814600123,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":5}
{"Event":"SparkListenerUnpersistRDD","RDD ID":4}
{"Event":"SparkListenerJobStart","Job ID":4,"Submission Time":1448814610030,"Stage Infos":[{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814610000\",\"name\":\"map @ 16:30:10\"}","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":8,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814610000\",\"name\":\"kafka direct stream [0]\\n@ 16:30:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[4],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448814610000\",\"name\":\"foreachRDD @ 16:30:10\"}","callSite.short":"foreachRDD at IdentityJob.scala:27","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448814610000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814610000\",\"name\":\"map @ 16:30:10\"}","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":8,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814610000\",\"name\":\"kafka direct stream [0]\\n@ 16:30:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448814610000\",\"name\":\"foreachRDD @ 16:30:10\"}","callSite.short":"foreachRDD at IdentityJob.scala:27","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448814610000"}}
{"Event":"SparkListenerTaskStart","Stage ID":4,"Stage Attempt ID":0,"Task Info":{"Task ID":4,"Index":0,"Attempt":0,"Launch Time":1448814610052,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":4,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":4,"Index":0,"Attempt":0,"Launch Time":1448814610052,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448814610128,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":47,"Executor Run Time":14,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":9,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814610000\",\"name\":\"map @ 16:30:10\"}","Parent IDs":[8],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":8,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814610000\",\"name\":\"kafka direct stream [0]\\n@ 16:30:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448814610051,"Completion Time":1448814610129,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":4,"Completion Time":1448814610130,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":7}
{"Event":"SparkListenerUnpersistRDD","RDD ID":6}
{"Event":"SparkListenerJobStart","Job ID":5,"Submission Time":1448814620033,"Stage Infos":[{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":11,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814620000\",\"name\":\"map @ 16:30:20\"}","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":10,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814620000\",\"name\":\"kafka direct stream [0]\\n@ 16:30:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[5],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448814620000\",\"name\":\"foreachRDD @ 16:30:20\"}","callSite.short":"foreachRDD at IdentityJob.scala:27","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448814620000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":11,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814620000\",\"name\":\"map @ 16:30:20\"}","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":10,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814620000\",\"name\":\"kafka direct stream [0]\\n@ 16:30:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448814620000\",\"name\":\"foreachRDD @ 16:30:20\"}","callSite.short":"foreachRDD at IdentityJob.scala:27","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448814620000"}}
{"Event":"SparkListenerTaskStart","Stage ID":5,"Stage Attempt ID":0,"Task Info":{"Task ID":5,"Index":0,"Attempt":0,"Launch Time":1448814620048,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":5,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":5,"Index":0,"Attempt":0,"Launch Time":1448814620048,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448814620103,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":26,"Executor Run Time":15,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":11,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814620000\",\"name\":\"map @ 16:30:20\"}","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":10,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814620000\",\"name\":\"kafka direct stream [0]\\n@ 16:30:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448814620047,"Completion Time":1448814620103,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":5,"Completion Time":1448814620103,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":9}
{"Event":"SparkListenerUnpersistRDD","RDD ID":8}
{"Event":"SparkListenerJobStart","Job ID":6,"Submission Time":1448814630035,"Stage Infos":[{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814630000\",\"name\":\"map @ 16:30:30\"}","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":12,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814630000\",\"name\":\"kafka direct stream [0]\\n@ 16:30:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[6],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448814630000\",\"name\":\"foreachRDD @ 16:30:30\"}","callSite.short":"foreachRDD at IdentityJob.scala:27","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448814630000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814630000\",\"name\":\"map @ 16:30:30\"}","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":12,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814630000\",\"name\":\"kafka direct stream [0]\\n@ 16:30:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448814630000\",\"name\":\"foreachRDD @ 16:30:30\"}","callSite.short":"foreachRDD at IdentityJob.scala:27","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448814630000"}}
{"Event":"SparkListenerTaskStart","Stage ID":6,"Stage Attempt ID":0,"Task Info":{"Task ID":6,"Index":0,"Attempt":0,"Launch Time":1448814630055,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":6,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":6,"Index":0,"Attempt":0,"Launch Time":1448814630055,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448814630123,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":38,"Executor Run Time":15,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814630000\",\"name\":\"map @ 16:30:30\"}","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":12,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814630000\",\"name\":\"kafka direct stream [0]\\n@ 16:30:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448814630054,"Completion Time":1448814630124,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":6,"Completion Time":1448814630125,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":11}
{"Event":"SparkListenerUnpersistRDD","RDD ID":10}
{"Event":"SparkListenerJobStart","Job ID":7,"Submission Time":1448814640032,"Stage Infos":[{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":15,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814640000\",\"name\":\"map @ 16:30:40\"}","Parent IDs":[14],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":14,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814640000\",\"name\":\"kafka direct stream [0]\\n@ 16:30:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[7],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448814640000\",\"name\":\"foreachRDD @ 16:30:40\"}","callSite.short":"foreachRDD at IdentityJob.scala:27","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448814640000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":15,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814640000\",\"name\":\"map @ 16:30:40\"}","Parent IDs":[14],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":14,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814640000\",\"name\":\"kafka direct stream [0]\\n@ 16:30:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448814640000\",\"name\":\"foreachRDD @ 16:30:40\"}","callSite.short":"foreachRDD at IdentityJob.scala:27","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448814640000"}}
{"Event":"SparkListenerTaskStart","Stage ID":7,"Stage Attempt ID":0,"Task Info":{"Task ID":7,"Index":0,"Attempt":0,"Launch Time":1448814640051,"Executor ID":"0","Host":"10.0.1.37","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":7,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":7,"Index":0,"Attempt":0,"Launch Time":1448814640051,"Executor ID":"0","Host":"10.0.1.37","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448814642344,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.37","Executor Deserialize Time":2028,"Executor Run Time":221,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":15,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814640000\",\"name\":\"map @ 16:30:40\"}","Parent IDs":[14],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":14,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814640000\",\"name\":\"kafka direct stream [0]\\n@ 16:30:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448814640050,"Completion Time":1448814642345,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":7,"Completion Time":1448814642345,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":13}
{"Event":"SparkListenerUnpersistRDD","RDD ID":12}
{"Event":"SparkListenerJobStart","Job ID":8,"Submission Time":1448814650023,"Stage Infos":[{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":17,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814650000\",\"name\":\"map @ 16:30:50\"}","Parent IDs":[16],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":16,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814650000\",\"name\":\"kafka direct stream [0]\\n@ 16:30:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[8],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448814650000\",\"name\":\"foreachRDD @ 16:30:50\"}","callSite.short":"foreachRDD at IdentityJob.scala:27","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448814650000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":17,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814650000\",\"name\":\"map @ 16:30:50\"}","Parent IDs":[16],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":16,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814650000\",\"name\":\"kafka direct stream [0]\\n@ 16:30:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448814650000\",\"name\":\"foreachRDD @ 16:30:50\"}","callSite.short":"foreachRDD at IdentityJob.scala:27","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448814650000"}}
{"Event":"SparkListenerTaskStart","Stage ID":8,"Stage Attempt ID":0,"Task Info":{"Task ID":8,"Index":0,"Attempt":0,"Launch Time":1448814650038,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":8,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":8,"Index":0,"Attempt":0,"Launch Time":1448814650038,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448814650311,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":23,"Executor Run Time":235,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":17,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814650000\",\"name\":\"map @ 16:30:50\"}","Parent IDs":[16],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":16,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814650000\",\"name\":\"kafka direct stream [0]\\n@ 16:30:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448814650038,"Completion Time":1448814650312,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":8,"Completion Time":1448814650312,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":15}
{"Event":"SparkListenerUnpersistRDD","RDD ID":14}
{"Event":"SparkListenerJobStart","Job ID":9,"Submission Time":1448814660035,"Stage Infos":[{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814660000\",\"name\":\"map @ 16:31:00\"}","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":18,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814660000\",\"name\":\"kafka direct stream [0]\\n@ 16:31:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[9],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448814660000\",\"name\":\"foreachRDD @ 16:31:00\"}","callSite.short":"foreachRDD at IdentityJob.scala:27","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448814660000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814660000\",\"name\":\"map @ 16:31:00\"}","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":18,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814660000\",\"name\":\"kafka direct stream [0]\\n@ 16:31:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448814660000\",\"name\":\"foreachRDD @ 16:31:00\"}","callSite.short":"foreachRDD at IdentityJob.scala:27","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448814660000"}}
{"Event":"SparkListenerTaskStart","Stage ID":9,"Stage Attempt ID":0,"Task Info":{"Task ID":9,"Index":0,"Attempt":0,"Launch Time":1448814660050,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":9,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":9,"Index":0,"Attempt":0,"Launch Time":1448814660050,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448814660096,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":30,"Executor Run Time":1,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814660000\",\"name\":\"map @ 16:31:00\"}","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":18,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814660000\",\"name\":\"kafka direct stream [0]\\n@ 16:31:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448814660052,"Completion Time":1448814660097,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":9,"Completion Time":1448814660097,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":17}
{"Event":"SparkListenerUnpersistRDD","RDD ID":16}
{"Event":"SparkListenerJobStart","Job ID":10,"Submission Time":1448814670036,"Stage Infos":[{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":21,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814670000\",\"name\":\"map @ 16:31:10\"}","Parent IDs":[20],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":20,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814670000\",\"name\":\"kafka direct stream [0]\\n@ 16:31:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[10],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448814670000\",\"name\":\"foreachRDD @ 16:31:10\"}","callSite.short":"foreachRDD at IdentityJob.scala:27","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448814670000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":21,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814670000\",\"name\":\"map @ 16:31:10\"}","Parent IDs":[20],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":20,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814670000\",\"name\":\"kafka direct stream [0]\\n@ 16:31:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448814670000\",\"name\":\"foreachRDD @ 16:31:10\"}","callSite.short":"foreachRDD at IdentityJob.scala:27","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448814670000"}}
{"Event":"SparkListenerTaskStart","Stage ID":10,"Stage Attempt ID":0,"Task Info":{"Task ID":10,"Index":0,"Attempt":0,"Launch Time":1448814670053,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":10,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":10,"Index":0,"Attempt":0,"Launch Time":1448814670053,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448814670099,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":31,"Executor Run Time":0,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"foreachRDD at IdentityJob.scala:27","Number of Tasks":1,"RDD Info":[{"RDD ID":21,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448814670000\",\"name\":\"map @ 16:31:10\"}","Parent IDs":[20],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":20,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448814670000\",\"name\":\"kafka direct stream [0]\\n@ 16:31:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.IdentityJob.processStreamData(IdentityJob.scala:27)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:84)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448814670052,"Completion Time":1448814670100,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":10,"Completion Time":1448814670100,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":19}
{"Event":"SparkListenerUnpersistRDD","RDD ID":18}
