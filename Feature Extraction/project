{"Event":"SparkListenerLogStart","Spark Version":"1.5.0"}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"driver","Host":"10.0.1.35","Port":52042},"Maximum Memory":2223023063,"Timestamp":1448824076736}
{"Event":"SparkListenerEnvironmentUpdate","JVM Information":{"Java Home":"/usr/lib/jvm/java-7-openjdk-amd64/jre","Java Version":"1.7.0_85 (Oracle Corporation)","Scala Version":"version 2.10.4"},"Spark Properties":{"spark.akka.timeout":"600","spark.driver.host":"10.0.1.35","spark.kryoserializer.buffer.mb":"2000","spark.broadcast.compress":"false","spark.io.compression.codec":"org.apache.spark.io.SnappyCompressionCodec","spark.eventLog.enabled":"true","spark.driver.port":"40117","spark.rdd.compress":"false","spark.cleaner.ttl":"7200","spark.shuffle.compress":"false","spark.jars":"file:/home/ubuntu/software/HiBench-master/src/streambench/sparkbench/target/streaming-bench-spark_0.1-4.0-SNAPSHOT-jar-with-dependencies.jar,file:/home/ubuntu/software/HiBench-master/src/sparkbench/target/sparkbench-4.0-SNAPSHOT-MR2-spark1.5-jar-with-dependencies.jar","spark.app.name":"project","spark.scheduler.mode":"FIFO","spark.driver.memory":"4G","spark.default.parallelism":"12","spark.executor.id":"driver","spark.submit.deployMode":"client","spark.master":"spark://10.0.1.35:7077","spark.executor.memory":"4G","spark.eventLog.dir":"/home/ubuntu/storage/logs/HiBench","spark.fileserver.uri":"http://10.0.1.35:53256","spark.externalBlockStore.folderName":"spark-8bbba71a-5a85-4e68-89ba-d6422a5149d3","spark.app.id":"app-20151129190756-0030","spark.akka.frameSize":"1000","spark.sql.shuffle.partitions":"12"},"System Properties":{"java.io.tmpdir":"/tmp","line.separator":"\n","path.separator":":","sun.management.compiler":"HotSpot 64-Bit Tiered Compilers","SPARK_SUBMIT":"true","sun.cpu.endian":"little","java.specification.version":"1.7","java.vm.specification.name":"Java Virtual Machine Specification","java.vendor":"Oracle Corporation","java.vm.specification.version":"1.7","user.home":"/home/ubuntu","file.encoding.pkg":"sun.io","sun.nio.ch.bugLevel":"","sun.arch.data.model":"64","sun.boot.library.path":"/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/amd64","user.dir":"/home/ubuntu/software/HiBench-master/workloads/streamingbench/spark/bin","java.library.path":"/home/ubuntu/software/hadoop-2.6.0/share/hadoop/common/lib/native/::/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib","sun.cpu.isalist":"","os.arch":"amd64","java.vm.version":"24.85-b03","java.endorsed.dirs":"/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/endorsed","java.runtime.version":"1.7.0_85-b01","java.vm.info":"mixed mode","java.ext.dirs":"/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/ext:/usr/java/packages/lib/ext","java.runtime.name":"OpenJDK Runtime Environment","file.separator":"/","java.class.version":"51.0","java.specification.name":"Java Platform API Specification","sun.boot.class.path":"/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/resources.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/rt.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/sunrsasign.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/jsse.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/jce.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/charsets.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/rhino.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/lib/jfr.jar:/usr/lib/jvm/java-7-openjdk-amd64/jre/classes","file.encoding":"UTF-8","user.timezone":"Etc/UTC","java.specification.vendor":"Oracle Corporation","sun.java.launcher":"SUN_STANDARD","os.version":"3.13.0-46-generic","sun.os.patch.level":"unknown","java.vm.specification.vendor":"Oracle Corporation","user.country":"US","sun.jnu.encoding":"UTF-8","user.language":"en","java.vendor.url":"http://java.oracle.com/","java.awt.printerjob":"sun.print.PSPrinterJob","java.awt.graphicsenv":"sun.awt.X11GraphicsEnvironment","awt.toolkit":"sun.awt.X11.XToolkit","os.name":"Linux","java.vm.vendor":"Oracle Corporation","java.vendor.url.bug":"http://bugreport.sun.com/bugreport/","user.name":"ubuntu","java.vm.name":"OpenJDK 64-Bit Server VM","sun.java.command":"org.apache.spark.deploy.SparkSubmit --master spark://10.0.1.35:7077 --properties-file /home/ubuntu/software/HiBench-master/report/streamingbench/spark/conf/sparkbench/spark.conf --class com.intel.hibench.streambench.spark.RunBench --jars /home/ubuntu/software/HiBench-master/src/streambench/sparkbench/target/streaming-bench-spark_0.1-4.0-SNAPSHOT-jar-with-dependencies.jar /home/ubuntu/software/HiBench-master/src/sparkbench/target/sparkbench-4.0-SNAPSHOT-MR2-spark1.5-jar-with-dependencies.jar /home/ubuntu/software/HiBench-master/report/streamingbench/spark/conf/sparkbench/sparkbench.conf","java.home":"/usr/lib/jvm/java-7-openjdk-amd64/jre","java.version":"1.7.0_85","sun.io.unicode.encoding":"UnicodeLittle"},"Classpath Entries":{"/home/ubuntu/software/spark-1.5.0-bin-hadoop2.6/lib/datanucleus-api-jdo-3.2.6.jar":"System Classpath","/home/ubuntu/conf/":"System Classpath","/home/ubuntu/software/spark-1.5.0-bin-hadoop2.6/lib/datanucleus-rdbms-3.2.9.jar":"System Classpath","/home/ubuntu/software/spark-1.5.0-bin-hadoop2.6/lib/spark-assembly-1.5.0-hadoop2.6.0.jar":"System Classpath","/home/ubuntu/software/spark-1.5.0-bin-hadoop2.6/lib/datanucleus-core-3.2.10.jar":"System Classpath","http://10.0.1.35:53256/jars/streaming-bench-spark_0.1-4.0-SNAPSHOT-jar-with-dependencies.jar":"Added By User"}}
{"Event":"SparkListenerApplicationStart","App Name":"project","App ID":"app-20151129190756-0030","Timestamp":1448824073333,"User":"ubuntu"}
{"Event":"SparkListenerExecutorAdded","Timestamp":1448824079888,"Executor ID":"3","Executor Info":{"Host":"10.0.1.38","Total Cores":5,"Log Urls":{"stdout":"http://10.0.1.38:8081/logPage/?appId=app-20151129190756-0030&executorId=3&logType=stdout","stderr":"http://10.0.1.38:8081/logPage/?appId=app-20151129190756-0030&executorId=3&logType=stderr"}}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1448824079927,"Executor ID":"0","Executor Info":{"Host":"10.0.1.37","Total Cores":5,"Log Urls":{"stdout":"http://10.0.1.37:8081/logPage/?appId=app-20151129190756-0030&executorId=0&logType=stdout","stderr":"http://10.0.1.37:8081/logPage/?appId=app-20151129190756-0030&executorId=0&logType=stderr"}}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1448824079943,"Executor ID":"2","Executor Info":{"Host":"10.0.1.36","Total Cores":5,"Log Urls":{"stdout":"http://10.0.1.36:8081/logPage/?appId=app-20151129190756-0030&executorId=2&logType=stdout","stderr":"http://10.0.1.36:8081/logPage/?appId=app-20151129190756-0030&executorId=2&logType=stderr"}}}
{"Event":"SparkListenerExecutorAdded","Timestamp":1448824080009,"Executor ID":"1","Executor Info":{"Host":"10.0.1.35","Total Cores":5,"Log Urls":{"stdout":"http://10.0.1.35:8081/logPage/?appId=app-20151129190756-0030&executorId=1&logType=stdout","stderr":"http://10.0.1.35:8081/logPage/?appId=app-20151129190756-0030&executorId=1&logType=stderr"}}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"3","Host":"10.0.1.38","Port":36609},"Maximum Memory":2223023063,"Timestamp":1448824080100}
{"Event":"SparkListenerJobStart","Job ID":0,"Submission Time":1448824080125,"Stage Infos":[{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":2,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824080000\",\"name\":\"foreachRDD @ 19:08:00\"}","Parent IDs":[1],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824080000\",\"name\":\"kafka direct stream [0]\\n@ 19:08:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824080000\",\"name\":\"map @ 19:08:00\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[0],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824080000\",\"name\":\"foreachRDD @ 19:08:00\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824080000"}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"0","Host":"10.0.1.37","Port":56670},"Maximum Memory":2223023063,"Timestamp":1448824080130}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":2,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824080000\",\"name\":\"foreachRDD @ 19:08:00\"}","Parent IDs":[1],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824080000\",\"name\":\"kafka direct stream [0]\\n@ 19:08:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824080000\",\"name\":\"map @ 19:08:00\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824080000\",\"name\":\"foreachRDD @ 19:08:00\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824080000"}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"2","Host":"10.0.1.36","Port":34802},"Maximum Memory":2223023063,"Timestamp":1448824080157}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Launch Time":1448824080271,"Executor ID":"0","Host":"10.0.1.37","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerBlockManagerAdded","Block Manager ID":{"Executor ID":"1","Host":"10.0.1.35","Port":58745},"Maximum Memory":2223023063,"Timestamp":1448824080905}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":0,"Index":0,"Attempt":0,"Launch Time":1448824080271,"Executor ID":"0","Host":"10.0.1.37","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824082817,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.37","Executor Deserialize Time":2226,"Executor Run Time":235,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":2,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824080000\",\"name\":\"foreachRDD @ 19:08:00\"}","Parent IDs":[1],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824080000\",\"name\":\"kafka direct stream [0]\\n@ 19:08:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":1,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824080000\",\"name\":\"map @ 19:08:00\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824080265,"Completion Time":1448824082825,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":0,"Completion Time":1448824082830,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":1,"Submission Time":1448824090047,"Stage Infos":[{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":5,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824090000\",\"name\":\"foreachRDD @ 19:08:10\"}","Parent IDs":[4],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":4,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824090000\",\"name\":\"map @ 19:08:10\"}","Parent IDs":[3],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":3,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824090000\",\"name\":\"kafka direct stream [0]\\n@ 19:08:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[1],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824090000\",\"name\":\"foreachRDD @ 19:08:10\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824090000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":5,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824090000\",\"name\":\"foreachRDD @ 19:08:10\"}","Parent IDs":[4],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":4,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824090000\",\"name\":\"map @ 19:08:10\"}","Parent IDs":[3],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":3,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824090000\",\"name\":\"kafka direct stream [0]\\n@ 19:08:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824090000\",\"name\":\"foreachRDD @ 19:08:10\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824090000"}}
{"Event":"SparkListenerTaskStart","Stage ID":1,"Stage Attempt ID":0,"Task Info":{"Task ID":1,"Index":0,"Attempt":0,"Launch Time":1448824090065,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":1,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":1,"Index":0,"Attempt":0,"Launch Time":1448824090065,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824092631,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.36","Executor Deserialize Time":2296,"Executor Run Time":215,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":5,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824090000\",\"name\":\"foreachRDD @ 19:08:10\"}","Parent IDs":[4],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":4,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824090000\",\"name\":\"map @ 19:08:10\"}","Parent IDs":[3],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":3,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824090000\",\"name\":\"kafka direct stream [0]\\n@ 19:08:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824090064,"Completion Time":1448824092632,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":1,"Completion Time":1448824092632,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":1}
{"Event":"SparkListenerUnpersistRDD","RDD ID":0}
{"Event":"SparkListenerJobStart","Job ID":2,"Submission Time":1448824100041,"Stage Infos":[{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":8,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824100000\",\"name\":\"foreachRDD @ 19:08:20\"}","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":6,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824100000\",\"name\":\"kafka direct stream [0]\\n@ 19:08:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824100000\",\"name\":\"map @ 19:08:20\"}","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[2],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824100000\",\"name\":\"foreachRDD @ 19:08:20\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824100000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":8,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824100000\",\"name\":\"foreachRDD @ 19:08:20\"}","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":6,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824100000\",\"name\":\"kafka direct stream [0]\\n@ 19:08:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824100000\",\"name\":\"map @ 19:08:20\"}","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824100000\",\"name\":\"foreachRDD @ 19:08:20\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824100000"}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":2,"Index":0,"Attempt":0,"Launch Time":1448824100057,"Executor ID":"3","Host":"10.0.1.38","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":2,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":2,"Index":0,"Attempt":0,"Launch Time":1448824100057,"Executor ID":"3","Host":"10.0.1.38","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824125767,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.38","Executor Deserialize Time":25229,"Executor Run Time":426,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":8,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824100000\",\"name\":\"foreachRDD @ 19:08:20\"}","Parent IDs":[7],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":6,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824100000\",\"name\":\"kafka direct stream [0]\\n@ 19:08:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":7,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824100000\",\"name\":\"map @ 19:08:20\"}","Parent IDs":[6],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824100056,"Completion Time":1448824125769,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":2,"Completion Time":1448824125769,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":4}
{"Event":"SparkListenerUnpersistRDD","RDD ID":3}
{"Event":"SparkListenerJobStart","Job ID":3,"Submission Time":1448824125792,"Stage Infos":[{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824110000\",\"name\":\"foreachRDD @ 19:08:30\"}","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":9,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824110000\",\"name\":\"kafka direct stream [0]\\n@ 19:08:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":10,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824110000\",\"name\":\"map @ 19:08:30\"}","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[3],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824110000\",\"name\":\"foreachRDD @ 19:08:30\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824110000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824110000\",\"name\":\"foreachRDD @ 19:08:30\"}","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":9,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824110000\",\"name\":\"kafka direct stream [0]\\n@ 19:08:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":10,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824110000\",\"name\":\"map @ 19:08:30\"}","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824110000\",\"name\":\"foreachRDD @ 19:08:30\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824110000"}}
{"Event":"SparkListenerTaskStart","Stage ID":3,"Stage Attempt ID":0,"Task Info":{"Task ID":3,"Index":0,"Attempt":0,"Launch Time":1448824125807,"Executor ID":"0","Host":"10.0.1.37","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":3,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":3,"Index":0,"Attempt":0,"Launch Time":1448824125807,"Executor ID":"0","Host":"10.0.1.37","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824125913,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.37","Executor Deserialize Time":31,"Executor Run Time":61,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":3,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":13,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824110000\",\"name\":\"foreachRDD @ 19:08:30\"}","Parent IDs":[10],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":9,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824110000\",\"name\":\"kafka direct stream [0]\\n@ 19:08:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":10,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824110000\",\"name\":\"map @ 19:08:30\"}","Parent IDs":[9],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824125806,"Completion Time":1448824125914,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":3,"Completion Time":1448824125914,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":7}
{"Event":"SparkListenerUnpersistRDD","RDD ID":6}
{"Event":"SparkListenerJobStart","Job ID":4,"Submission Time":1448824125934,"Stage Infos":[{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":14,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824120000\",\"name\":\"foreachRDD @ 19:08:40\"}","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":11,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824120000\",\"name\":\"kafka direct stream [0]\\n@ 19:08:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824120000\",\"name\":\"map @ 19:08:40\"}","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[4],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824120000\",\"name\":\"foreachRDD @ 19:08:40\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824120000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":14,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824120000\",\"name\":\"foreachRDD @ 19:08:40\"}","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":11,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824120000\",\"name\":\"kafka direct stream [0]\\n@ 19:08:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824120000\",\"name\":\"map @ 19:08:40\"}","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824120000\",\"name\":\"foreachRDD @ 19:08:40\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824120000"}}
{"Event":"SparkListenerTaskStart","Stage ID":4,"Stage Attempt ID":0,"Task Info":{"Task ID":4,"Index":0,"Attempt":0,"Launch Time":1448824125947,"Executor ID":"0","Host":"10.0.1.37","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":4,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":4,"Index":0,"Attempt":0,"Launch Time":1448824125947,"Executor ID":"0","Host":"10.0.1.37","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824126045,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.37","Executor Deserialize Time":27,"Executor Run Time":58,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":4,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":14,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824120000\",\"name\":\"foreachRDD @ 19:08:40\"}","Parent IDs":[12],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":11,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824120000\",\"name\":\"kafka direct stream [0]\\n@ 19:08:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":12,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824120000\",\"name\":\"map @ 19:08:40\"}","Parent IDs":[11],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824125947,"Completion Time":1448824126045,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":4,"Completion Time":1448824126045,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":10}
{"Event":"SparkListenerUnpersistRDD","RDD ID":9}
{"Event":"SparkListenerJobStart","Job ID":5,"Submission Time":1448824130037,"Stage Infos":[{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":17,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824130000\",\"name\":\"foreachRDD @ 19:08:50\"}","Parent IDs":[16],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":15,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824130000\",\"name\":\"kafka direct stream [0]\\n@ 19:08:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":16,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824130000\",\"name\":\"map @ 19:08:50\"}","Parent IDs":[15],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[5],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824130000\",\"name\":\"foreachRDD @ 19:08:50\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824130000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":17,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824130000\",\"name\":\"foreachRDD @ 19:08:50\"}","Parent IDs":[16],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":15,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824130000\",\"name\":\"kafka direct stream [0]\\n@ 19:08:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":16,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824130000\",\"name\":\"map @ 19:08:50\"}","Parent IDs":[15],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824130000\",\"name\":\"foreachRDD @ 19:08:50\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824130000"}}
{"Event":"SparkListenerTaskStart","Stage ID":5,"Stage Attempt ID":0,"Task Info":{"Task ID":5,"Index":0,"Attempt":0,"Launch Time":1448824130052,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":5,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":5,"Index":0,"Attempt":0,"Launch Time":1448824130052,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824130167,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.36","Executor Deserialize Time":45,"Executor Run Time":53,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":5,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":17,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824130000\",\"name\":\"foreachRDD @ 19:08:50\"}","Parent IDs":[16],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":15,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824130000\",\"name\":\"kafka direct stream [0]\\n@ 19:08:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":16,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824130000\",\"name\":\"map @ 19:08:50\"}","Parent IDs":[15],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824130053,"Completion Time":1448824130168,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":5,"Completion Time":1448824130168,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":12}
{"Event":"SparkListenerUnpersistRDD","RDD ID":11}
{"Event":"SparkListenerJobStart","Job ID":6,"Submission Time":1448824140040,"Stage Infos":[{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":20,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824140000\",\"name\":\"foreachRDD @ 19:09:00\"}","Parent IDs":[19],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824140000\",\"name\":\"map @ 19:09:00\"}","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":18,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824140000\",\"name\":\"kafka direct stream [0]\\n@ 19:09:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[6],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824140000\",\"name\":\"foreachRDD @ 19:09:00\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824140000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":20,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824140000\",\"name\":\"foreachRDD @ 19:09:00\"}","Parent IDs":[19],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824140000\",\"name\":\"map @ 19:09:00\"}","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":18,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824140000\",\"name\":\"kafka direct stream [0]\\n@ 19:09:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824140000\",\"name\":\"foreachRDD @ 19:09:00\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824140000"}}
{"Event":"SparkListenerTaskStart","Stage ID":6,"Stage Attempt ID":0,"Task Info":{"Task ID":6,"Index":0,"Attempt":0,"Launch Time":1448824140058,"Executor ID":"3","Host":"10.0.1.38","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":6,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":6,"Index":0,"Attempt":0,"Launch Time":1448824140058,"Executor ID":"3","Host":"10.0.1.38","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824140179,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.38","Executor Deserialize Time":47,"Executor Run Time":55,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":6,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":20,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824140000\",\"name\":\"foreachRDD @ 19:09:00\"}","Parent IDs":[19],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":19,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824140000\",\"name\":\"map @ 19:09:00\"}","Parent IDs":[18],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":18,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824140000\",\"name\":\"kafka direct stream [0]\\n@ 19:09:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824140058,"Completion Time":1448824140180,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":6,"Completion Time":1448824140181,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":16}
{"Event":"SparkListenerUnpersistRDD","RDD ID":15}
{"Event":"SparkListenerJobStart","Job ID":7,"Submission Time":1448824150028,"Stage Infos":[{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824150000\",\"name\":\"foreachRDD @ 19:09:10\"}","Parent IDs":[22],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":21,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824150000\",\"name\":\"kafka direct stream [0]\\n@ 19:09:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":22,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824150000\",\"name\":\"map @ 19:09:10\"}","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[7],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824150000\",\"name\":\"foreachRDD @ 19:09:10\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824150000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824150000\",\"name\":\"foreachRDD @ 19:09:10\"}","Parent IDs":[22],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":21,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824150000\",\"name\":\"kafka direct stream [0]\\n@ 19:09:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":22,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824150000\",\"name\":\"map @ 19:09:10\"}","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824150000\",\"name\":\"foreachRDD @ 19:09:10\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824150000"}}
{"Event":"SparkListenerTaskStart","Stage ID":7,"Stage Attempt ID":0,"Task Info":{"Task ID":7,"Index":0,"Attempt":0,"Launch Time":1448824150041,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":7,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":7,"Index":0,"Attempt":0,"Launch Time":1448824150041,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824150142,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.36","Executor Deserialize Time":38,"Executor Run Time":48,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":7,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":23,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824150000\",\"name\":\"foreachRDD @ 19:09:10\"}","Parent IDs":[22],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":21,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824150000\",\"name\":\"kafka direct stream [0]\\n@ 19:09:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":22,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824150000\",\"name\":\"map @ 19:09:10\"}","Parent IDs":[21],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824150040,"Completion Time":1448824150143,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":7,"Completion Time":1448824150143,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":19}
{"Event":"SparkListenerUnpersistRDD","RDD ID":18}
{"Event":"SparkListenerJobStart","Job ID":8,"Submission Time":1448824160040,"Stage Infos":[{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":26,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824160000\",\"name\":\"foreachRDD @ 19:09:20\"}","Parent IDs":[25],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":25,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824160000\",\"name\":\"map @ 19:09:20\"}","Parent IDs":[24],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":24,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824160000\",\"name\":\"kafka direct stream [0]\\n@ 19:09:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[8],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824160000\",\"name\":\"foreachRDD @ 19:09:20\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824160000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":26,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824160000\",\"name\":\"foreachRDD @ 19:09:20\"}","Parent IDs":[25],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":25,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824160000\",\"name\":\"map @ 19:09:20\"}","Parent IDs":[24],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":24,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824160000\",\"name\":\"kafka direct stream [0]\\n@ 19:09:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824160000\",\"name\":\"foreachRDD @ 19:09:20\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824160000"}}
{"Event":"SparkListenerTaskStart","Stage ID":8,"Stage Attempt ID":0,"Task Info":{"Task ID":8,"Index":0,"Attempt":0,"Launch Time":1448824160056,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":8,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":8,"Index":0,"Attempt":0,"Launch Time":1448824160056,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824162090,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":1777,"Executor Run Time":204,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":8,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":26,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824160000\",\"name\":\"foreachRDD @ 19:09:20\"}","Parent IDs":[25],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":25,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824160000\",\"name\":\"map @ 19:09:20\"}","Parent IDs":[24],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":24,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824160000\",\"name\":\"kafka direct stream [0]\\n@ 19:09:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824160056,"Completion Time":1448824162091,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":8,"Completion Time":1448824162092,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":22}
{"Event":"SparkListenerUnpersistRDD","RDD ID":21}
{"Event":"SparkListenerJobStart","Job ID":9,"Submission Time":1448824170030,"Stage Infos":[{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":29,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824170000\",\"name\":\"foreachRDD @ 19:09:30\"}","Parent IDs":[28],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":28,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824170000\",\"name\":\"map @ 19:09:30\"}","Parent IDs":[27],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":27,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824170000\",\"name\":\"kafka direct stream [0]\\n@ 19:09:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[9],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824170000\",\"name\":\"foreachRDD @ 19:09:30\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824170000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":29,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824170000\",\"name\":\"foreachRDD @ 19:09:30\"}","Parent IDs":[28],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":28,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824170000\",\"name\":\"map @ 19:09:30\"}","Parent IDs":[27],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":27,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824170000\",\"name\":\"kafka direct stream [0]\\n@ 19:09:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824170000\",\"name\":\"foreachRDD @ 19:09:30\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824170000"}}
{"Event":"SparkListenerTaskStart","Stage ID":9,"Stage Attempt ID":0,"Task Info":{"Task ID":9,"Index":0,"Attempt":0,"Launch Time":1448824170043,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":9,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":9,"Index":0,"Attempt":0,"Launch Time":1448824170043,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824170160,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.36","Executor Deserialize Time":46,"Executor Run Time":51,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":9,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":29,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824170000\",\"name\":\"foreachRDD @ 19:09:30\"}","Parent IDs":[28],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":28,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824170000\",\"name\":\"map @ 19:09:30\"}","Parent IDs":[27],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":27,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824170000\",\"name\":\"kafka direct stream [0]\\n@ 19:09:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824170042,"Completion Time":1448824170160,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":9,"Completion Time":1448824170160,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":25}
{"Event":"SparkListenerUnpersistRDD","RDD ID":24}
{"Event":"SparkListenerJobStart","Job ID":10,"Submission Time":1448824180032,"Stage Infos":[{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":32,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824180000\",\"name\":\"foreachRDD @ 19:09:40\"}","Parent IDs":[31],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":31,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824180000\",\"name\":\"map @ 19:09:40\"}","Parent IDs":[30],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":30,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824180000\",\"name\":\"kafka direct stream [0]\\n@ 19:09:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[10],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824180000\",\"name\":\"foreachRDD @ 19:09:40\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824180000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":32,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824180000\",\"name\":\"foreachRDD @ 19:09:40\"}","Parent IDs":[31],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":31,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824180000\",\"name\":\"map @ 19:09:40\"}","Parent IDs":[30],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":30,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824180000\",\"name\":\"kafka direct stream [0]\\n@ 19:09:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824180000\",\"name\":\"foreachRDD @ 19:09:40\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824180000"}}
{"Event":"SparkListenerTaskStart","Stage ID":10,"Stage Attempt ID":0,"Task Info":{"Task ID":10,"Index":0,"Attempt":0,"Launch Time":1448824180050,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":10,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":10,"Index":0,"Attempt":0,"Launch Time":1448824180050,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824180164,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.36","Executor Deserialize Time":39,"Executor Run Time":58,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":10,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":32,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824180000\",\"name\":\"foreachRDD @ 19:09:40\"}","Parent IDs":[31],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":31,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824180000\",\"name\":\"map @ 19:09:40\"}","Parent IDs":[30],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":30,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824180000\",\"name\":\"kafka direct stream [0]\\n@ 19:09:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824180050,"Completion Time":1448824180165,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":10,"Completion Time":1448824180165,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":28}
{"Event":"SparkListenerUnpersistRDD","RDD ID":27}
{"Event":"SparkListenerJobStart","Job ID":11,"Submission Time":1448824190030,"Stage Infos":[{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":35,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824190000\",\"name\":\"foreachRDD @ 19:09:50\"}","Parent IDs":[34],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":33,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824190000\",\"name\":\"kafka direct stream [0]\\n@ 19:09:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":34,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824190000\",\"name\":\"map @ 19:09:50\"}","Parent IDs":[33],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[11],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824190000\",\"name\":\"foreachRDD @ 19:09:50\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824190000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":35,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824190000\",\"name\":\"foreachRDD @ 19:09:50\"}","Parent IDs":[34],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":33,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824190000\",\"name\":\"kafka direct stream [0]\\n@ 19:09:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":34,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824190000\",\"name\":\"map @ 19:09:50\"}","Parent IDs":[33],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824190000\",\"name\":\"foreachRDD @ 19:09:50\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824190000"}}
{"Event":"SparkListenerTaskStart","Stage ID":11,"Stage Attempt ID":0,"Task Info":{"Task ID":11,"Index":0,"Attempt":0,"Launch Time":1448824190046,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":11,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":11,"Index":0,"Attempt":0,"Launch Time":1448824190046,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824190157,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.36","Executor Deserialize Time":41,"Executor Run Time":52,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":11,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":35,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824190000\",\"name\":\"foreachRDD @ 19:09:50\"}","Parent IDs":[34],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":33,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824190000\",\"name\":\"kafka direct stream [0]\\n@ 19:09:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":34,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824190000\",\"name\":\"map @ 19:09:50\"}","Parent IDs":[33],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824190045,"Completion Time":1448824190158,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":11,"Completion Time":1448824190158,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":31}
{"Event":"SparkListenerUnpersistRDD","RDD ID":30}
{"Event":"SparkListenerJobStart","Job ID":12,"Submission Time":1448824200032,"Stage Infos":[{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":38,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824200000\",\"name\":\"foreachRDD @ 19:10:00\"}","Parent IDs":[37],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":36,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824200000\",\"name\":\"kafka direct stream [0]\\n@ 19:10:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":37,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824200000\",\"name\":\"map @ 19:10:00\"}","Parent IDs":[36],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[12],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824200000\",\"name\":\"foreachRDD @ 19:10:00\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824200000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":38,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824200000\",\"name\":\"foreachRDD @ 19:10:00\"}","Parent IDs":[37],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":36,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824200000\",\"name\":\"kafka direct stream [0]\\n@ 19:10:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":37,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824200000\",\"name\":\"map @ 19:10:00\"}","Parent IDs":[36],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824200000\",\"name\":\"foreachRDD @ 19:10:00\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824200000"}}
{"Event":"SparkListenerTaskStart","Stage ID":12,"Stage Attempt ID":0,"Task Info":{"Task ID":12,"Index":0,"Attempt":0,"Launch Time":1448824200048,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":12,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":12,"Index":0,"Attempt":0,"Launch Time":1448824200048,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824200132,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":34,"Executor Run Time":33,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":12,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":38,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824200000\",\"name\":\"foreachRDD @ 19:10:00\"}","Parent IDs":[37],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":36,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824200000\",\"name\":\"kafka direct stream [0]\\n@ 19:10:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":37,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824200000\",\"name\":\"map @ 19:10:00\"}","Parent IDs":[36],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824200047,"Completion Time":1448824200133,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":12,"Completion Time":1448824200133,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":34}
{"Event":"SparkListenerUnpersistRDD","RDD ID":33}
{"Event":"SparkListenerJobStart","Job ID":13,"Submission Time":1448824210037,"Stage Infos":[{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824210000\",\"name\":\"foreachRDD @ 19:10:10\"}","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":39,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824210000\",\"name\":\"kafka direct stream [0]\\n@ 19:10:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":40,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824210000\",\"name\":\"map @ 19:10:10\"}","Parent IDs":[39],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[13],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824210000\",\"name\":\"foreachRDD @ 19:10:10\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824210000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824210000\",\"name\":\"foreachRDD @ 19:10:10\"}","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":39,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824210000\",\"name\":\"kafka direct stream [0]\\n@ 19:10:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":40,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824210000\",\"name\":\"map @ 19:10:10\"}","Parent IDs":[39],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824210000\",\"name\":\"foreachRDD @ 19:10:10\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824210000"}}
{"Event":"SparkListenerTaskStart","Stage ID":13,"Stage Attempt ID":0,"Task Info":{"Task ID":13,"Index":0,"Attempt":0,"Launch Time":1448824210053,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":13,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":13,"Index":0,"Attempt":0,"Launch Time":1448824210053,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824210167,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.36","Executor Deserialize Time":43,"Executor Run Time":53,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":13,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":41,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824210000\",\"name\":\"foreachRDD @ 19:10:10\"}","Parent IDs":[40],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":39,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824210000\",\"name\":\"kafka direct stream [0]\\n@ 19:10:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":40,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824210000\",\"name\":\"map @ 19:10:10\"}","Parent IDs":[39],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824210052,"Completion Time":1448824210168,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":13,"Completion Time":1448824210169,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":37}
{"Event":"SparkListenerUnpersistRDD","RDD ID":36}
{"Event":"SparkListenerJobStart","Job ID":14,"Submission Time":1448824220033,"Stage Infos":[{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":44,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824220000\",\"name\":\"foreachRDD @ 19:10:20\"}","Parent IDs":[43],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824220000\",\"name\":\"map @ 19:10:20\"}","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":42,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824220000\",\"name\":\"kafka direct stream [0]\\n@ 19:10:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[14],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824220000\",\"name\":\"foreachRDD @ 19:10:20\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824220000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":44,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824220000\",\"name\":\"foreachRDD @ 19:10:20\"}","Parent IDs":[43],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824220000\",\"name\":\"map @ 19:10:20\"}","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":42,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824220000\",\"name\":\"kafka direct stream [0]\\n@ 19:10:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824220000\",\"name\":\"foreachRDD @ 19:10:20\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824220000"}}
{"Event":"SparkListenerTaskStart","Stage ID":14,"Stage Attempt ID":0,"Task Info":{"Task ID":14,"Index":0,"Attempt":0,"Launch Time":1448824220047,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":14,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":14,"Index":0,"Attempt":0,"Launch Time":1448824220047,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824220117,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":27,"Executor Run Time":30,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":14,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":44,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824220000\",\"name\":\"foreachRDD @ 19:10:20\"}","Parent IDs":[43],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":43,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824220000\",\"name\":\"map @ 19:10:20\"}","Parent IDs":[42],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":42,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824220000\",\"name\":\"kafka direct stream [0]\\n@ 19:10:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824220047,"Completion Time":1448824220117,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":14,"Completion Time":1448824220117,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":40}
{"Event":"SparkListenerUnpersistRDD","RDD ID":39}
{"Event":"SparkListenerJobStart","Job ID":15,"Submission Time":1448824230025,"Stage Infos":[{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":47,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824230000\",\"name\":\"foreachRDD @ 19:10:30\"}","Parent IDs":[46],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824230000\",\"name\":\"map @ 19:10:30\"}","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":45,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824230000\",\"name\":\"kafka direct stream [0]\\n@ 19:10:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[15],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824230000\",\"name\":\"foreachRDD @ 19:10:30\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824230000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":47,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824230000\",\"name\":\"foreachRDD @ 19:10:30\"}","Parent IDs":[46],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824230000\",\"name\":\"map @ 19:10:30\"}","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":45,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824230000\",\"name\":\"kafka direct stream [0]\\n@ 19:10:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824230000\",\"name\":\"foreachRDD @ 19:10:30\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824230000"}}
{"Event":"SparkListenerTaskStart","Stage ID":15,"Stage Attempt ID":0,"Task Info":{"Task ID":15,"Index":0,"Attempt":0,"Launch Time":1448824230037,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":15,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":15,"Index":0,"Attempt":0,"Launch Time":1448824230037,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824230111,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":26,"Executor Run Time":29,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":15,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":47,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824230000\",\"name\":\"foreachRDD @ 19:10:30\"}","Parent IDs":[46],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":46,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824230000\",\"name\":\"map @ 19:10:30\"}","Parent IDs":[45],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":45,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824230000\",\"name\":\"kafka direct stream [0]\\n@ 19:10:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824230037,"Completion Time":1448824230113,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":15,"Completion Time":1448824230113,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":43}
{"Event":"SparkListenerUnpersistRDD","RDD ID":42}
{"Event":"SparkListenerJobStart","Job ID":16,"Submission Time":1448824240029,"Stage Infos":[{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":50,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824240000\",\"name\":\"foreachRDD @ 19:10:40\"}","Parent IDs":[49],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824240000\",\"name\":\"map @ 19:10:40\"}","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":48,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824240000\",\"name\":\"kafka direct stream [0]\\n@ 19:10:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[16],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824240000\",\"name\":\"foreachRDD @ 19:10:40\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824240000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":50,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824240000\",\"name\":\"foreachRDD @ 19:10:40\"}","Parent IDs":[49],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824240000\",\"name\":\"map @ 19:10:40\"}","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":48,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824240000\",\"name\":\"kafka direct stream [0]\\n@ 19:10:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824240000\",\"name\":\"foreachRDD @ 19:10:40\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824240000"}}
{"Event":"SparkListenerTaskStart","Stage ID":16,"Stage Attempt ID":0,"Task Info":{"Task ID":16,"Index":0,"Attempt":0,"Launch Time":1448824240042,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":16,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":16,"Index":0,"Attempt":0,"Launch Time":1448824240042,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824240158,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.36","Executor Deserialize Time":42,"Executor Run Time":53,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":16,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":50,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824240000\",\"name\":\"foreachRDD @ 19:10:40\"}","Parent IDs":[49],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":49,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824240000\",\"name\":\"map @ 19:10:40\"}","Parent IDs":[48],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":48,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824240000\",\"name\":\"kafka direct stream [0]\\n@ 19:10:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824240042,"Completion Time":1448824240159,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":16,"Completion Time":1448824240159,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":46}
{"Event":"SparkListenerUnpersistRDD","RDD ID":45}
{"Event":"SparkListenerJobStart","Job ID":17,"Submission Time":1448824250027,"Stage Infos":[{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":53,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824250000\",\"name\":\"foreachRDD @ 19:10:50\"}","Parent IDs":[52],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":51,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824250000\",\"name\":\"kafka direct stream [0]\\n@ 19:10:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":52,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824250000\",\"name\":\"map @ 19:10:50\"}","Parent IDs":[51],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[17],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824250000\",\"name\":\"foreachRDD @ 19:10:50\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824250000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":53,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824250000\",\"name\":\"foreachRDD @ 19:10:50\"}","Parent IDs":[52],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":51,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824250000\",\"name\":\"kafka direct stream [0]\\n@ 19:10:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":52,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824250000\",\"name\":\"map @ 19:10:50\"}","Parent IDs":[51],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824250000\",\"name\":\"foreachRDD @ 19:10:50\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824250000"}}
{"Event":"SparkListenerTaskStart","Stage ID":17,"Stage Attempt ID":0,"Task Info":{"Task ID":17,"Index":0,"Attempt":0,"Launch Time":1448824250041,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":17,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":17,"Index":0,"Attempt":0,"Launch Time":1448824250041,"Executor ID":"2","Host":"10.0.1.36","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824250145,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.36","Executor Deserialize Time":41,"Executor Run Time":49,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":17,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":53,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824250000\",\"name\":\"foreachRDD @ 19:10:50\"}","Parent IDs":[52],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":51,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824250000\",\"name\":\"kafka direct stream [0]\\n@ 19:10:50\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":52,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824250000\",\"name\":\"map @ 19:10:50\"}","Parent IDs":[51],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824250040,"Completion Time":1448824250145,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":17,"Completion Time":1448824250146,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":49}
{"Event":"SparkListenerUnpersistRDD","RDD ID":48}
{"Event":"SparkListenerJobStart","Job ID":18,"Submission Time":1448824260030,"Stage Infos":[{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":56,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824260000\",\"name\":\"foreachRDD @ 19:11:00\"}","Parent IDs":[55],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":54,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824260000\",\"name\":\"kafka direct stream [0]\\n@ 19:11:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":55,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824260000\",\"name\":\"map @ 19:11:00\"}","Parent IDs":[54],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[18],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824260000\",\"name\":\"foreachRDD @ 19:11:00\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824260000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":56,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824260000\",\"name\":\"foreachRDD @ 19:11:00\"}","Parent IDs":[55],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":54,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824260000\",\"name\":\"kafka direct stream [0]\\n@ 19:11:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":55,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824260000\",\"name\":\"map @ 19:11:00\"}","Parent IDs":[54],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824260000\",\"name\":\"foreachRDD @ 19:11:00\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824260000"}}
{"Event":"SparkListenerTaskStart","Stage ID":18,"Stage Attempt ID":0,"Task Info":{"Task ID":18,"Index":0,"Attempt":0,"Launch Time":1448824260045,"Executor ID":"0","Host":"10.0.1.37","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":18,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":18,"Index":0,"Attempt":0,"Launch Time":1448824260045,"Executor ID":"0","Host":"10.0.1.37","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824260151,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.37","Executor Deserialize Time":34,"Executor Run Time":56,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":1,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":18,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":56,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824260000\",\"name\":\"foreachRDD @ 19:11:00\"}","Parent IDs":[55],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":54,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824260000\",\"name\":\"kafka direct stream [0]\\n@ 19:11:00\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":55,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824260000\",\"name\":\"map @ 19:11:00\"}","Parent IDs":[54],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824260044,"Completion Time":1448824260152,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":18,"Completion Time":1448824260152,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":52}
{"Event":"SparkListenerUnpersistRDD","RDD ID":51}
{"Event":"SparkListenerJobStart","Job ID":19,"Submission Time":1448824270023,"Stage Infos":[{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":59,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824270000\",\"name\":\"foreachRDD @ 19:11:10\"}","Parent IDs":[58],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":57,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824270000\",\"name\":\"kafka direct stream [0]\\n@ 19:11:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":58,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824270000\",\"name\":\"map @ 19:11:10\"}","Parent IDs":[57],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[19],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824270000\",\"name\":\"foreachRDD @ 19:11:10\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824270000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":59,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824270000\",\"name\":\"foreachRDD @ 19:11:10\"}","Parent IDs":[58],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":57,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824270000\",\"name\":\"kafka direct stream [0]\\n@ 19:11:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":58,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824270000\",\"name\":\"map @ 19:11:10\"}","Parent IDs":[57],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824270000\",\"name\":\"foreachRDD @ 19:11:10\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824270000"}}
{"Event":"SparkListenerTaskStart","Stage ID":19,"Stage Attempt ID":0,"Task Info":{"Task ID":19,"Index":0,"Attempt":0,"Launch Time":1448824270039,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":19,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":19,"Index":0,"Attempt":0,"Launch Time":1448824270039,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824270740,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":29,"Executor Run Time":660,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":19,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":59,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824270000\",\"name\":\"foreachRDD @ 19:11:10\"}","Parent IDs":[58],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":57,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824270000\",\"name\":\"kafka direct stream [0]\\n@ 19:11:10\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":58,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824270000\",\"name\":\"map @ 19:11:10\"}","Parent IDs":[57],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824270039,"Completion Time":1448824270740,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":19,"Completion Time":1448824270740,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":55}
{"Event":"SparkListenerUnpersistRDD","RDD ID":54}
{"Event":"SparkListenerJobStart","Job ID":20,"Submission Time":1448824280032,"Stage Infos":[{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":62,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824280000\",\"name\":\"foreachRDD @ 19:11:20\"}","Parent IDs":[61],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":60,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824280000\",\"name\":\"kafka direct stream [0]\\n@ 19:11:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":61,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824280000\",\"name\":\"map @ 19:11:20\"}","Parent IDs":[60],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[20],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824280000\",\"name\":\"foreachRDD @ 19:11:20\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824280000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":62,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824280000\",\"name\":\"foreachRDD @ 19:11:20\"}","Parent IDs":[61],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":60,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824280000\",\"name\":\"kafka direct stream [0]\\n@ 19:11:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":61,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824280000\",\"name\":\"map @ 19:11:20\"}","Parent IDs":[60],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824280000\",\"name\":\"foreachRDD @ 19:11:20\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824280000"}}
{"Event":"SparkListenerTaskStart","Stage ID":20,"Stage Attempt ID":0,"Task Info":{"Task ID":20,"Index":0,"Attempt":0,"Launch Time":1448824280045,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":20,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":20,"Index":0,"Attempt":0,"Launch Time":1448824280045,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824280240,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":29,"Executor Run Time":154,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":20,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":62,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824280000\",\"name\":\"foreachRDD @ 19:11:20\"}","Parent IDs":[61],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":60,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824280000\",\"name\":\"kafka direct stream [0]\\n@ 19:11:20\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":61,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824280000\",\"name\":\"map @ 19:11:20\"}","Parent IDs":[60],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824280045,"Completion Time":1448824280242,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":20,"Completion Time":1448824280242,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":58}
{"Event":"SparkListenerUnpersistRDD","RDD ID":57}
{"Event":"SparkListenerJobStart","Job ID":21,"Submission Time":1448824290027,"Stage Infos":[{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":65,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824290000\",\"name\":\"foreachRDD @ 19:11:30\"}","Parent IDs":[64],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":64,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824290000\",\"name\":\"map @ 19:11:30\"}","Parent IDs":[63],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":63,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824290000\",\"name\":\"kafka direct stream [0]\\n@ 19:11:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[21],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824290000\",\"name\":\"foreachRDD @ 19:11:30\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824290000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":65,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824290000\",\"name\":\"foreachRDD @ 19:11:30\"}","Parent IDs":[64],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":64,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824290000\",\"name\":\"map @ 19:11:30\"}","Parent IDs":[63],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":63,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824290000\",\"name\":\"kafka direct stream [0]\\n@ 19:11:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824290000\",\"name\":\"foreachRDD @ 19:11:30\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824290000"}}
{"Event":"SparkListenerTaskStart","Stage ID":21,"Stage Attempt ID":0,"Task Info":{"Task ID":21,"Index":0,"Attempt":0,"Launch Time":1448824290043,"Executor ID":"0","Host":"10.0.1.37","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":21,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":21,"Index":0,"Attempt":0,"Launch Time":1448824290043,"Executor ID":"0","Host":"10.0.1.37","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824290090,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.37","Executor Deserialize Time":31,"Executor Run Time":1,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":21,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":65,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824290000\",\"name\":\"foreachRDD @ 19:11:30\"}","Parent IDs":[64],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":64,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824290000\",\"name\":\"map @ 19:11:30\"}","Parent IDs":[63],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":63,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824290000\",\"name\":\"kafka direct stream [0]\\n@ 19:11:30\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824290042,"Completion Time":1448824290091,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":21,"Completion Time":1448824290091,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":61}
{"Event":"SparkListenerUnpersistRDD","RDD ID":60}
{"Event":"SparkListenerJobStart","Job ID":22,"Submission Time":1448824300033,"Stage Infos":[{"Stage ID":22,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":68,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824300000\",\"name\":\"foreachRDD @ 19:11:40\"}","Parent IDs":[67],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":66,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824300000\",\"name\":\"kafka direct stream [0]\\n@ 19:11:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":67,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824300000\",\"name\":\"map @ 19:11:40\"}","Parent IDs":[66],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]}],"Stage IDs":[22],"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824300000\",\"name\":\"foreachRDD @ 19:11:40\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824300000"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":22,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":68,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824300000\",\"name\":\"foreachRDD @ 19:11:40\"}","Parent IDs":[67],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":66,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824300000\",\"name\":\"kafka direct stream [0]\\n@ 19:11:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":67,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824300000\",\"name\":\"map @ 19:11:40\"}","Parent IDs":[66],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Accumulables":[]},"Properties":{"callSite.long":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","spark.rdd.scope":"{\"id\":\"2_1448824300000\",\"name\":\"foreachRDD @ 19:11:40\"}","callSite.short":"foreachRDD at StreamProjectionJob.scala:32","spark.streaming.internal.outputOpId":"0","spark.rdd.scope.noOverride":"true","spark.streaming.internal.batchTime":"1448824300000"}}
{"Event":"SparkListenerTaskStart","Stage ID":22,"Stage Attempt ID":0,"Task Info":{"Task ID":22,"Index":0,"Attempt":0,"Launch Time":1448824300049,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":22,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":22,"Index":0,"Attempt":0,"Launch Time":1448824300049,"Executor ID":"1","Host":"10.0.1.35","Locality":"ANY","Speculative":false,"Getting Result Time":0,"Finish Time":1448824300095,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"10.0.1.35","Executor Deserialize Time":31,"Executor Run Time":0,"Result Size":915,"JVM GC Time":0,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":22,"Stage Attempt ID":0,"Stage Name":"foreachRDD at StreamProjectionJob.scala:32","Number of Tasks":1,"RDD Info":[{"RDD ID":68,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"2_1448824300000\",\"name\":\"foreachRDD @ 19:11:40\"}","Parent IDs":[67],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":66,"Name":"KafkaRDD","Scope":"{\"id\":\"0_1448824300000\",\"name\":\"kafka direct stream [0]\\n@ 19:11:40\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":67,"Name":"MapPartitionsRDD","Scope":"{\"id\":\"1_1448824300000\",\"name\":\"map @ 19:11:40\"}","Parent IDs":[66],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":1,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.streaming.dstream.DStream.foreachRDD(DStream.scala:629)\ncom.intel.hibench.streambench.spark.microbench.StreamProjectionJob.processStreamData(StreamProjectionJob.scala:32)\ncom.intel.hibench.streambench.spark.microbench.RunBenchJobWithInit.run(RunBenchWithInit.scala:56)\ncom.intel.hibench.streambench.spark.RunBench$.run(RunBench.scala:59)\ncom.intel.hibench.streambench.spark.RunBench$.main(RunBench.scala:26)\ncom.intel.hibench.streambench.spark.RunBench.main(RunBench.scala)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:606)\norg.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)\norg.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)\norg.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)\norg.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)\norg.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)","Submission Time":1448824300048,"Completion Time":1448824300096,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":22,"Completion Time":1448824300096,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerUnpersistRDD","RDD ID":64}
{"Event":"SparkListenerUnpersistRDD","RDD ID":63}
